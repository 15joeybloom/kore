\documentclass[UTF8,11pt]{article}

  % Package for using the full page.
  \usepackage{fullpage}
  
  % Package for writing algorithms (why do we need this one?).
  \usepackage[linesnumbered,ruled,vlined]{algorithm2e}
  
  % Package for using colored texts.
  \usepackage[pdftex,dvipsnames]{xcolor}
  
  % Pakcage for using multiple optional parameters in new commands.
  \usepackage{xargs}

  % Packages for writing comments and todo notes.
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  \newcommandx{\unsure}[2][1=]
    {\todo[linecolor=red,backgroundcolor=red!25,
	bordercolor=red,#1]
	{#2}\xspace{}}
  \newcommandx{\change}[2][1=]
    {\todo[linecolor=blue,backgroundcolor=blue!25,
	bordercolor=blue,#1]
	{#2}\xspace{}}
  \newcommandx{\info}[2][1=]
    {\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,
	bordercolor=OliveGreen,#1]
	{#2}}
  \newcommandx{\improvement}[2][1=]
    {\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]
	{#2}\xspace{}}
  \newcommandx{\thiswillnotshow}[2][1=]
    {\todo[disable,#1]
	{#2}\xspace{}}

  % What are there for?
  % Select what to do with todonotes: 
  % \usepackage[disable]{todonotes} % notes not showed
  % \usepackage[draft]  {todonotes} % notes showed

  % Select what to do with command \comment:  
  % \newcommand{\comment}[1]
      {}                                    %comment not showed
  \newcommand{\comment}[1]
    {\par {\bfseries \color{blue} #1 \par}} %comment showed
  
  % ams math packages.
  \usepackage{amsmath, amssymb, amsthm}
  
  % Declare a global counter for theorem environments:
  \newcounter{thmcounter}
  
  % Define new theorem styles and theorem environments.
  \theoremstyle{plain}
  
  \newtheorem{theorem}    [thmcounter]{Theorem}
  \newtheorem{corollary}  [thmcounter]{Corollary}
  \newtheorem{lemma}      [thmcounter]{Lemma}
  \newtheorem{proposition}[thmcounter]{Proposition}
  
  \theoremstyle{definition}
  
  \newtheorem{definition} [thmcounter]{Definition}
  \newtheorem{example}    [thmcounter]{Example}
  
  \theoremstyle{remark}
  
  \newtheorem{remark}     [thmcounter]{Remark}
  \newtheorem{notation}   [thmcounter]{Notation}
  
  
  % Package for changing fonts in the Verbatim environment:
  \usepackage{fancyvrb}
  
  % Package for writing captions for align environment:
  \usepackage{capt-of}
  
  % Package for URLs:
  \usepackage{hyperref}  
  
  % Package for tables:
  \usepackage[english]{babel}  
  
  % Package for quotations:
  \usepackage{csquotes}
  
  % Package for customizing lists environments:
  \usepackage{enumitem}
  
  % Package for graphics
  \usepackage{graphicx}
  
  % Define ceiling and flooring symbols:
  \usepackage{mathtools}
  \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
  \DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

  % Package for underlining and strikethrough texts.
  \usepackage[normalem]{ulem}
  
  % Package for display-mode quotations.
  \usepackage{csquotes}
  
  % Define double-bracket [[P]]
  \usepackage{stmaryrd}
  \newcommand{\Bracket}[1]{\llbracket#1\rrbracket}
  
  % Package for writing natural proof deductions
  \usepackage{prftree}
    
  % Package for writing BNF syntax
  \usepackage{syntax}
  
  % Package for using the symbol "§", e.g., "Section §3.1".
  % Use \cref{label} to cite Secctions.
  \usepackage[utf8]{inputenc}
  \usepackage{cleveref}
  \crefname{section}{§}{§§}
  
  % Package for lstlisting and definition of Kore
  \usepackage{listings}
  % Define colors
  \definecolor{codegray}{rgb}{0.5,0.5,0.5}
  \definecolor{backgray}{RGB}{250,250,250}
  \definecolor{codegreen}{RGB}{50,205,50}
  \definecolor{codeblue}{RGB}{50,50,255}
  % Define Kore Language style
  \lstdefinelanguage{kore}
  {
  	% print whole listing small and in serif fonts
  	basicstyle=\ttfamily\footnotesize,
  	% use /* */ for comments
  	morecomment=[s]{/*}{*/},
  	% print white for comments
  	commentstyle=\color{codegray},
  	% print line number in the left, in tiny fonts
  	numbers=left,
  	numberstyle=\tiny,
  	% print all characters at their natural width
  	columns=fullflexible,
  	% print background color grey
  	backgroundcolor=\color{backgray},
  	% regard some characters as letters
  	alsoletter={-\\},
  	% list of declaration keywords
  	keywordstyle=[1]\color{codeblue},
  	morekeywords=[1]{
  		module,
  		endmodule,
  		hooked-sort,
  		sort,
  		symbol,
  		hooked-symbol,
  		alias,
  		axiom,
  	},
    % list of connectives
    keywordstyle=[2]\color{codegreen},
    morekeywords=[2]{
    	\\not,
    	\\or,
    	\\implies,
    	\\and,
    	\\equals,
    	\\exists,
    	\\forall,
    	\\iff
    }
  }

  % Define |-fin
  \newcommand{\vdashfin}{\vdash_\text{fin}}

  % Define the colon ":" that is used in "x:s"
  % with less spacing around.
  \newcommand{\cln}{{:}}

  % Define the curly K:
  \newcommand{\K}{\mbox{$\mathbb{K}$}\xspace}
  
  % Define commands that are used in Sec 2.  
  \newcommand{\Nat}{\textit{Nat}}
  \newcommand{\KNat}{\textit{KNat}}
  \newcommand{\Int}{\textit{Int}}
  \newcommand{\Bool}{\textit{Bool}}
  \newcommand{\List}{\textit{List}}
  \newcommand{\KList}{\textit{KList}}
  \newcommand{\nil}{\textit{nil}}
  \newcommand{\cons}{\textit{cons}}
  \newcommand{\append}{\textit{append}}
  \newcommand{\Bag}{\textit{Bag}}
  \newcommand{\Set}{\textit{Set}}
  \newcommand{\Map}{\textit{Map}}
  \newcommand{\emptyMap}{\textit{empty}}
  \newcommand{\bindMap}{\textit{bind}}
  \newcommand{\mergeMap}{\textit{merge}}

  \newcommand{\Context}{\textit{Context}}
  \newcommand{\hole}{\boxempty}
  \newcommand{\Exp}{\textit{Exp}}
  \newcommand{\AExp}{\textit{AExp}}
  \newcommand{\BExp}{\textit{BExp}}
  \newcommand{\Stmt}{\textit{Stmt}}
  \newcommand{\ite}{\textsf{ite}}
  \newcommand{\ttrue}{\textit{true}}
  \newcommand{\ffalse}{\textit{false}}
  \newcommand{\app}{\textit{app}}
  \newcommand{\KExp}{\mathit{\#Exp}}
  \newcommand{\Klambdazero}{\mathit{Klambda0}}
  \newcommand{\Kapp}{\mathit{Kapp}}
  \newcommand{\Klambda}{\mathit{Klambda}}
  \newcommand{\parametric}[2]{{#1}\raisebox{.2ex}{\texttt{\footnotesize{\{}}}#2\raisebox{.2ex}{\texttt{\footnotesize{\}}}}}
  \newcommand{\parametricscript}[2]{{#1}\raisebox{.2ex}{\texttt{\tiny{\{}}}#2\raisebox{.2ex}{\texttt{\tiny{\}}}}}
  
  \newcommand{\zero}{\textit{zero}}
  \newcommand{\Kzero}{\textit{Kzero}}
  \newcommand{\Ksucc}{\textit{Ksucc}}
  \newcommand{\KSymbolsucc}{\textit{KSymbolsucc}}
  \newcommand{\Mod}{\textit{Mod}}
  \newcommand{\denote}[1]{\llbracket{#1}\rrbracket}
  \newcommand{\reduct}[2]{\mbox{${#1}\!\!\upharpoonright_{#2}$}}
  \newcommand{\reductscript}[2]{\mbox{\tiny${#1}\!\!\upharpoonright_{#2}$}}
  
  \newcommand{\builtin}{\textit{builtin}}
  
  % Define PATTERNS with ATTERNS are small capitals:
  \newcommand{\PATTERNS}{\text{P\textsc{atterns}}}
  \newcommand{\VARIABLES}{\text{V\textsc{ariables}}}
  % Define sorts and symbols in the calculus K.
  
  \newcommand{\Kfinite}{{K_\text{finite}}}
  
  \newcommand{\shp}{\includegraphics{hash-symbol}\kern-0.1em}
  % Sec 3.1 Truth
  \newcommand{\KPred}{\mathit{\shp Pred}}
  
  %% We shouldn't need the follows.
  \newcommand{\Ktrue}{\mathit{\shp true}}
  \newcommand{\Kfalse}{\mathit{\shp false}}
  \newcommand{\KandBool}{\mathit{\shp andBool}}
  \newcommand{\KorBool}{\mathit{\shp orBool}}
  \newcommand{\KnotBool}{\mathit{\shp notBool}}
  \newcommand{\KimpliesBool}{\mathit{\shp impliesBool}}
  
  % Sec 3.2 Strings
  \newcommand{\KChar}{\mathit{\shp Char}}
  \newcommand{\KCharList}{\mathit{\shp CharList}}
  \newcommand{\KString}{\mathit{\shp String}}
  \newcommand{\Kepsilon}{\mathit{\shp epsilon}}
  \newcommand{\KconsKString}{\mathit{\shp consKString}}
  
  %% We shouldn't need the follows.  
  \newcommand{\Kconcat}{\mathit{\shp concat}}
  
  % Sec 3.3 Sorts and Symbols
  \newcommand{\KSort}{\mathit{\shp Sort}}
  \newcommand{\Ksort}{\mathit{\shp sort}}
  \newcommand{\KSymbol}{\mathit{\shp Symbol}}
  \newcommand{\Ksymbol}{\mathit{\shp symbol}}
  \newcommand{\KSymbolceil}{\mathit{\shp Symbolceil}}
  \newcommand{\KgetArgumentSorts}{\mathit{\shp getArgumentSorts}}
  \newcommand{\KgetReturnSort}{\mathit{\shp getReturnSort}}
  
  % Sec 3.4 Finite Lists
  \newcommand{\XList}{\mathit{XList}}
  \newcommand{\KnilXList}{\mathit{\shp nilXList}}
  \newcommand{\KconsXList}{\mathit{\shp consXList}}
  \newcommand{\KappendXList}{\mathit{\shp appendXList}}
  \newcommand{\KinXList}{\mathit{\shp inXList}}
  \newcommand{\KdeleteXList}{\mathit{\shp deleteXList}}
  \newcommand{\KPatternList}{\mathit{\shp PatternList}}
  \newcommand{\KnilKPatternList}{\mathit{\shp nilKPatternList}}
  \newcommand{\KconsKPatternList}{\mathit{\shp consKPatternList}}
  \newcommand{\KappendKPatternList}{\mathit{\shp appendKPatternList}}
  \newcommand{\KinKPatternList}{\mathit{\shp inKPatternList}}
  \newcommand{\KdeleteKPatternList}{\mathit{\shp deleteKPatternList}}
  \newcommand{\KSortList}{\mathit{\shp SortList}}
  \newcommand{\KnilKSortList}{\mathit{\shp nilKSortList}}
  \newcommand{\KconsKSortList}{\mathit{\shp consKSortList}}
  \newcommand{\KappendKSortList}{\mathit{\shp appendKSortList}}
  \newcommand{\KinKSortList}{\mathit{\shp inKSortList}}
  \newcommand{\KdeleteKSortList}{\mathit{\shp deleteKSortList}}
  \newcommand{\KSymbolList}{\mathit{\shp SymbolList}}
  \newcommand{\KinKSymbolList}{\mathit{\shp inKSymbolList}}
  \newcommand{\KnilKCharList}{\mathit{\shp nilKCharList}}
  \newcommand{\KconsKCharList}{\mathit{\shp consKCharList}}
  \newcommand{\KVariableList}{\mathit{\shp VariableList}}
  \newcommand{\KnilKVariableList}{\mathit{\shp nilKVariableList}}
  \newcommand{\KconsKVariableList}{\mathit{\shp consKVariableList}}
  %% Define l1 @ l2 for list concatenation.
  \newcommand{\at}{@}

  \newcommand{\KVariable}{\mathit{\shp Variable}}
  \newcommand{\KVariableToKPattern}{\mathit{\shp VariableToKPattern}}
  \newcommand{\KPattern}{\mathit{\shp Pattern}}
  \newcommand{\Kvariable}{\mathit{\shp variable}}
  \newcommand{\Kand}{\mathit{\shp and}}
  \newcommand{\Kor}{\mathit{\shp or}}
  \newcommand{\Kimplies}{\mathit{\shp implies}}
  \newcommand{\Kiff}{\mathit{\shp iff}}
  \newcommand{\Knot}{\mathit{\shp not}}
  \newcommand{\Kapplication}{\mathit{\shp application}}
  \newcommand{\Kexists}{\mathit{\shp exists}}
  \newcommand{\Kforall}{\mathit{\shp forall}}
  \newcommand{\Kequals}{\mathit{\shp equals}}
  \newcommand{\Kmembership}{\mathit{\shp mem}}
  \newcommand{\Kcontains}{\mathit{\shp contains}}
  \newcommand{\Ktop}{\mathit{\shp top}}
  \newcommand{\Kbottom}{\mathit{\shp bottom}}
  \newcommand{\Kfloor}{\mathit{\shp floor}}
  \newcommand{\Kceil}{\mathit{\shp ceil}}
  
  \newcommand{\KgetFvs}{\mathit{\shp getFvs}}
  \newcommand{\KgetFvsFromPatterns}{\mathit{\shp getFvsFromPatterns}}
  \newcommand{\KoccursFree}{\mathit{\shp occursFree}}
  \newcommand{\KfreshName}{\mathit{\shp freshName}}
  \newcommand{\Kcons}{\mathit{\shp cons}}
  \newcommand{\Knil}{\mathit{\shp nil}}
  \newcommand{\KSymbolzero}{\mathit{\shp Symbolzero}}
  \newcommand{\KSymbolcons}{\mathit{\shp Symbolcons}}
  \newcommand{\KSymbolnil}{\mathit{\shp Symbolnil}}
  
  \newcommand{\KSignature}{\mathit{\shp Signature}}
  \newcommand{\Ksignature}{\mathit{\shp signature}}
  \newcommand{\KgetSorts}{\mathit{\shp getSorts}}
  \newcommand{\KgetSymbols}{\mathit{\shp getSymbols}}
  \newcommand{\KsortDeclared}{\mathit{\shp sortDeclared}}
  \newcommand{\KsymbolDeclared}{\mathit{\shp symbolDeclared}}
  \newcommand{\KaxiomDeclared}{\mathit{\shp axiomDeclared}}
  \newcommand{\Kderivable}{\Kdeduce}
  
  \newcommand{\KwellFormed}{\mathit{\shp wellFormed}}
  \newcommand{\KwellFormedPatterns}{\mathit{\shp wellFormedPatterns}}
  \newcommand{\KgetSort}{\mathit{\shp getSort}}
  \newcommand{\KgetSortsFromPatterns}{\mathit{\shp getSortsFromPatterns}}
  \newcommand{\KisSort}{\mathit{\shp isSort}}
  \newcommand{\Ksubstitute}{\mathit{\shp substitute}}
  \newcommand{\KsubstitutePatterns}{\mathit{\shp substitutePatterns}}
  
  \newcommand{\KTheory}{\mathit{\shp Theory}}
  \newcommand{\Ktheory}{\mathit{\shp theory}}
  \newcommand{\KwellFormedTheory}{\mathit{\shp wellFormedTheory}}
  
  \newcommand{\Kdeduce}{\mathit{\shp provable}}
  
  % The italic font of "ceil" used in math mode.
  \newcommand{\cl}{\mathit{ceil}}
  
  % Use quotation marks "..." in math mode.
  \newcommand{\quot}[1]{\mathrm{``#1"}}

  \newcommand{\Pattern}{\textsc{Pattern}\xspace}
  \newcommand{\ra}{\rightarrow}
  \newcommand{\lra}{\leftrightarrow}
  \newcommand{\FV}{{\it FV}}
  
  \newcommand{\name}{\mathit{name}}
  \newcommand{\smalltt}[1]{\texttt{\small #1} }
  \newcommand{\sort}{\smalltt{sort}}
  \newcommand{\symb}{\smalltt{symbol}}
  \newcommand{\axiom}{\smalltt{axiom}}
  
  % Define slashed ttfamily words
  \newcommand{\sland}{\smalltt{\string\and}}
  \newcommand{\slor}{\smalltt{\string\or}}
  \newcommand{\slnot}{\smalltt{\string\not}}
  \newcommand{\slimplies}{\smalltt{\string\implies}}
  \newcommand{\sliff}{\smalltt{\string\iff}}
  \newcommand{\slequals}{\smalltt{\string\equals}}
  \newcommand{\slexists}{\smalltt{\string\exists}}
  \newcommand{\slforall}{\smalltt{\string\forall}}
  \newcommand{\sltop}{\smalltt{\string\top}}
  \newcommand{\slbottom}{\smalltt{\string\bottom}}
  \newcommand{\slceil}{\smalltt{\string\ceil}}
  \newcommand{\slfloor}{\smalltt{\string\floor}}
  % Title and authors
  \title{The Semantics of \K}
  \author{Formal Systems Laboratory \\
          University of Illinois at Urbana-Champaign}

\begin{document}

\maketitle

\info{Please feel free to contribute to this report in all ways.
You could add new contents, remove redundant ones, refactor and
organize the texts, and correct typos, but please follow the FSL
rules for editing, though; e.g., $<$80 characters per line,
each sentence on a new line, etc. }

\section{Introduction}
\label{sec:introduction}

\K is a best effort realization of matching logic~\cite{rosu-2017-lmcs}.
Matching logic allows us to mathematically define arbitrarily infinite
theories, which are not in general possible to describe finitely.
\K proposes a finitely describable subset of matching logic theories.
Since its inception in 2003 as a notation within
Maude~\cite{clavel-et-al99a} convenient for teaching programming
languages~\cite{rosu-2003-cs322}, until recently \K's semantics was explained
either by translation to rewriting logic \cite{meseguer-1992-tcs} or by
translation to some form of graph rewriting~\cite{serbanuta-rosu-2012-icgt}.
These translations not only added clutter and came at a loss of part of the
intended meaning of \K, but eventually turned out to be a serious limiting
factor in the types of theories and languages that could be defined.
Matching logic was specifically created and developed to serve as a
logical, semantic foundation for \K, after almost 15 years of experience
with using \K to define the formal semantics of real-life programming
languages, including
C~\cite{ellison-rosu-2012-popl,hathhorn-ellison-rosu-2015-pldi},
Java~\cite{bogdanas-rosu-2015-popl},
JavaScript~\cite{park-stefanescu-rosu-2015-pldi},
Python~\cite{guth-2013-thesis,pltredex-python},
PHP~\cite{k-php},
EVM~\cite{hiraidefining,hildenbrandt-saxena-zhu-rodrigues-daian-guth-rosu-2017-tr}.

Matching logic allows us to define \emph{theories} $(S,\Sigma,A)$ consisting
of potentially infinite sets of \emph{sorts} $S$, of \emph{symbols}
$\Sigma$ over sorts in $S$ (also called $S$-symbols), and of \emph{patterns}
$A$ built with symbols in $\Sigma$ (also called $\Sigma$-patterns),
respectively, and provides models that interpret the symbols
relationally, which in turn yield a \emph{semantic validity} relation
$(S,\Sigma,A)\models\varphi$ between theories $(S,\Sigma,A)$ and
$\Sigma$-patterns $\varphi$.
Matching logic also has a Hilbert-style complete proof system, which allows
us to derive new patterns $\varphi$ from given theories $(S,\Sigma,A)$,
written $(S,\Sigma,A)\vdash\varphi$.
When the sorts and signature are understood, we omit them; for example,
the completeness of matching logic then states that for any matching logic
theory $(S,\Sigma,A)$ and any $\Sigma$-pattern $\varphi$, we have
$A \models \varphi$ iff $A \vdash \varphi$.

...\improvement{Will add more here as we finalize the notation.
we need some convincing example.  Maybe parametric maps?}

\section{Matching Logic}
\label{sec:matching-logic}

\newcommand{\Var}{\textit{Var}}

In this section we first recall basic matching logic syntax and semantics
notions from~\cite{rosu-2017-lmcs} at a theoretical level.
\improvement{
We should make this paper self-contained in terms of definitions
and only refer to \cite{rosu-2017-lmcs} for details and proofs.
We want people who trust \cite{rosu-2017-lmcs} to not have to leave
this paper in order to understand the semantics of \K.
So we should define signatures, symbols, patterns, models,
satisfaction, proof system, etc.
}
Then we discuss schematic/parametric ways to finitely define infinite
matching logic theories.
Finally, we introduce theoretical foundations underlying the
notion of ``builtins''.

\subsection{Syntax}
\label{sec:ML-syntax}
Assume a matching logic \emph{signature} $(S, \Sigma)$, where $S$ is the
set of its \emph{sorts} $S$ and $\Sigma$ is the set of its \emph{symbols}.
When $S$ is understood, we write just $\Sigma$ for a signature instead of
$(S,\Sigma)$.
\improvement{We should mention here that $\wedge$, $\vee$, etc. are parametric on sorts.}
For each sort $s \in S$, assume a set $\Var_s$ of \emph{variables} of
sort $s$.
We partition $\Sigma$ in sets $\Sigma_{s_1 \ldots s_n, s}$ of symbols
of \emph{arity} $s_1\ldots s_n,s$, where
$s_1,\ldots, s_n, s \in S$.
The formulae of matching logic are called \emph{patterns}, although we
may also call them \emph{formulae}.
Patterns of sort $s \in S$ are generated by the following grammar:
\improvement{To be consistent with the meta-theory, we should introduce a set $\mathit{Name}$ of \emph{variable names}, and regard the colon ``$:$'' as a variable constructor that takes a name $x$ and a sort $s$, and constructs a variable $x \cln s$. We should not confuse variable names and variables. Otherwise it is very confusing when we introduce the meta-theory in later sections, because there we do view them differently.}
\begin{align*}
\varphi_s \Coloneqq\  &x \quad \text{where $x \in \Var_s$} 
\\
\mid\  &\sigma(\varphi_{s_1},...,\varphi_{s_n}) \quad\
\text{where $\sigma \in \Sigma_{s_1 \ldots s_n, s}$ and
$\varphi_{s_1},...,\varphi_{s_n}$ of appropriate sorts} \\
\mid\  &\varphi_s \wedge \varphi_s \\
\mid\  &\neg \varphi_s \\
\mid\  &\exists x \cln s' . \varphi_s \quad \text{where $x \in N$ and $s' \in S$}
\end{align*}
\begingroup\vspace*{-\baselineskip}
\captionof{figure}{The grammar of matching logic patterns.
For each $s\in S$, $\varphi_s$ are \emph{patterns of sort $s$}.}
\label{ml-grammar}
\vspace*{\baselineskip}\endgroup

Let \Pattern be the $S$-sorted set of patterns.
The grammar above can be infinite, i.e., can have infinitely many
non-terminals and productions, because $S$ and $\Sigma$ can be
infinite.
Also, as usual, it only defines the syntax of formulae and not
their semantics.
For example, patterns $x \wedge y$ and $y \wedge x$ are distinct elements in
the language of the grammar, in spite of them being semantically/provably
equal in matching logic.
For notational convenience, we take the liberty to use mix-fix syntax for
operators in $\Sigma$ and parentheses for grouping.
Also, we take the freedom to suffix variables with their sort preceded
by a colon whenever we want to clarify their sort in a pattern.
For example, if $\Nat \in S$ and
$\_+\_, \_*\_ \in \Sigma_{\Nat \times \Nat, \Nat}$
then we may write ``$(x\cln\Nat + y\cln\Nat)*z\cln\Nat$'' instead of
``$\_*\_(\_+\_(x,y),z)$ and $x,y,z\in\Nat$''.
More notational conventions will be introduced along the way
as we use them. 
We adopt the following derived constructs (``syntactic sugar''): %\vspace*{-1ex}
$$\begin{array}{rcl@{\hspace*{10ex}}rcl}
\top_{\!\!s} & \equiv & \exists x\!:\!s \,.\, x &
\varphi_1 \ra \varphi_2 & \equiv & \neg\varphi_1 \vee \varphi_2 \\
\bot_{s} & \equiv & \neg \top_{\!\!s} &
\varphi_1 \lra \varphi_2 & \equiv & (\varphi_1 \ra \varphi_2) \wedge
 (\varphi_2 \ra \varphi_1) \\
\varphi_1 \vee \varphi_2 & \equiv & \neg(\neg\varphi_1\wedge\neg\varphi_2) &
\forall x . \varphi & \equiv & \neg(\exists x . \neg\varphi) \\
%\varphi_1 = \varphi_2 & \equiv & \varphi_1 \lra \varphi_2
\end{array}
%\vspace*{-1ex}
$$
We adapt from first-order logic the notions of \emph{free variable}
($\FV(\varphi)$ is the set of free variables of $\varphi$) and of
variable-capture-free \emph{substitution} ($\varphi[\varphi'/x]$ denotes
$\varphi$ whose free occurrences of $x$ are replaced with $\varphi'$, possibly
renaming bound variables in $\varphi$ to avoid capturing free variables of
$\varphi'$).

A matching logic \emph{theory} is a triple $(S, \Sigma, A)$ where
$(S,\Sigma)$ is a signature and $A$ is a set of patterns called \emph{axioms}.
When $S$ is understood or not important, we write $(\Sigma,A)$ instead of $(S,\Sigma,A)$.

\subsection{Semantics and Basic Properties}
\label{sec:semantics}

A \emph{matching logic $(S,\Sigma)$-model} $M$ consists of:
An $S$-sorted set $\{M_s\}_{s\in S}$, where each set $M_s$,
called the \emph{carrier of sort $s$ of $M$}, is assumed
non-empty; and a function
$\sigma_M:M_{s_1}\times\cdots\times M_{s_n} \rightarrow {\cal P}(M_s)$
for each symbol $\sigma\in\Sigma_{s_1\ldots s_n,s}$, called the
\emph{interpretation} of $\sigma$ in $M$.
It is important to note that in matching logic symbols are interpreted as
functions into power-set domains, that is, as \emph{relations}, and not as
usual functions like in FOL.
We tacitly use the same notation $\sigma_M$ for its extension
to argument sets,
${\cal P}(M_{s_1})\times\cdots\times {\cal P}(M_{s_n}) \rightarrow {\cal P}(M_s)$.
When $S$ is understood we may call $M$ a \emph{$\Sigma$-model}, and when
both $S$ and $\Sigma$ are understood we call it simply a \emph{model}.
We let $\Mod(S,\Sigma)$, or $\Mod(\Sigma)$ when $S$ is understood, denote
the (category of) models of a signature $(S,\Sigma)$.
%
Given a model $M$ and a map
$\rho:\Var\rightarrow M$, called an \emph{$M$-valuation}, let its extension
$\overline{\rho}:\Pattern\rightarrow{\cal P}(M)$
be inductively defined as follows:\vspace*{-2ex}
\begin{itemize}\itemsep-1ex
\item $\overline{\rho}(x) = \{\rho(x)\}$, for all $x\in\Var_s$
\item $\overline{\rho}(\sigma(\varphi_{1},\ldots,\varphi_{n}))=
\sigma_M(\overline{\rho}(\varphi_1),\ldots \overline{\rho}(\varphi_n))$ for all
$\sigma\in\Sigma_{s_1...s_n,s}$ and appropriate $\varphi_1,...,\varphi_n$
%\item $\overline(\rho)(\top_{\!\!s}) = M_s$
\item $\overline{\rho}(\neg\varphi) = M_s \ \backslash\ \overline{\rho}(\varphi)$ for all
$\varphi\in\Pattern_s$
\item $\overline{\rho}(\varphi_1 \wedge \varphi_2) =
\overline{\rho}(\varphi_1) \cap \overline{\rho}(\varphi_2)$
for all $\varphi_1, \varphi_2$ patterns of the same sort
\item $\overline{\rho}(\exists x . \varphi) =
\bigcup\{\overline{\rho'}(\varphi) \mid \rho':\Var\rightarrow M,\ 
\rho'\!\!\upharpoonright_{\Var\backslash\{x\}} =
\rho\!\!\upharpoonright_{\Var\backslash\{x\}}\}
= \bigcup_{a\in M} \overline{\rho[a/x]}(\varphi)
$
\end{itemize}\vspace*{-.5ex}
where `` $\backslash$'' is set difference,
``$\rho\!\!\upharpoonright_V$'' is
$\rho$ restricted to $V \subseteq \Var$,
and ``$\rho[a/x]$'' is map $\rho'$ with $\rho'(x)=a$ and $\rho'(y)=\rho(y)$ if
$y\neq x$.
If $a\in \overline{\rho}(\varphi)$ then we say $a$ \emph{matches}
$\varphi$ (with witness $\rho$).

Pattern $\varphi_s$ is an \emph{$M$-predicate}, or a
\emph{predicate in $M$}, iff for any $M$-valuation $\rho:\Var\rightarrow M$,
it is the case that $\overline{\rho}(\varphi_s)$ is either $M_s$ (it holds) or
$\emptyset$ (it does not hold).
Pattern $\varphi_s$ is a \emph{predicate} iff it is a predicate in all
models $M$.
For example, $\top_s$ and $\bot_s$ are predicates, and if $\varphi$,
$\varphi_1$ and $\varphi_2$ are predicates then so are $\neg\varphi$,
$\varphi_1 \wedge \varphi_2$, and $\exists x\,.\,\varphi$.
That is, the logical connectives of matching logic preserve the predicate
nature of patterns.
Model $M$ \emph{satisfies} $\varphi_s$, written ${M}\models \varphi_s$, iff
$\overline{\rho}(\varphi_s) = M_s$ for all $\rho:\Var\rightarrow M$.
Pattern $\varphi$ is \emph{valid}, written $\models \varphi$,
iff ${M} \models \varphi$ for all ${M}$.
If $A\subseteq\Pattern$ then ${M} \models A$ iff
${M} \models \varphi$ for all $\varphi\in A$.
$A$ \emph{entails} $\varphi$, written $A \models \varphi$,
iff for each ${M}$, ${M} \models A$ implies ${M} \models \varphi$.
We may subscript $\models$ with the signature whenever we feel it
clarifies the presentation; that is, we may write $\models_{(S,\Sigma)}$ or
$\models_\Sigma$ instead of $\models$.
A \emph{matching logic specification} is a triple $(S,\Sigma,A)$, or
just $(\Sigma,A)$ when $S$ is understood, with $A$ a set of $\Sigma$-patterns.
Given matching logic specification $(\Sigma,A)$ we let
$\Mod(\Sigma,A)$, also denoted by $\denote{(\Sigma,A)}$ be its (category of)
models $\{M \ \mid \ M \in \Mod_{\Sigma},\ M \models_{\Sigma} A \}$.

A signature $(S',\Sigma')$ is called a \emph{subsignature} of $(S,\Sigma)$, written
$(S',\Sigma') \hookrightarrow(S,\Sigma)$, if and only if $S' \subseteq S$ and
$\Sigma' \subseteq \Sigma$.
If $M \in \Mod(\Sigma)$ then we let
$\reduct{M}{\Sigma'} \in \Mod(\Sigma')$ denote its
\emph{$\Sigma'$-reduct}, or simply its \emph{reduct} when
$\Sigma'$ is understood, defined as follows:
$(\reduct{M}{\Sigma'})_{s'} = M_{s'}$ for any $s'\in S'$ and
$\sigma'_{\reductscript{M}{\Sigma'}} = \sigma'_M$ for any $\sigma'\in\Sigma'$.
It may help to think of signatures as interfaces and of models as
\emph{implementations} of such interfaces.
Indeed, models provide concrete values for each sort, and concrete relations
for symbols.
Then the reduct $\reduct{M}{\Sigma'}$ can be regarded as a ``wrapper'' of
the implementation $M$ of $\Sigma$ turning it into an implementation of
$\Sigma'$, or a reuse of a richer implementation in a smaller context.

\subsection{Useful Symbols and Notations}
\label{sec:useful}

Matching logic is rather poor by default.
For example, it has no functions, no predicates, no equality, and although
symbols are interpreted as sets and variables are singletons, it has no
membership or inclusion.
All these operations are very useful, if not indispensable in practice.
Fortunately, they and many others can be defined axiomatically in matching
logic.
That is, whenever we need these in order to define (the semantics of other
symbols in) a matching logic specification $(\Sigma,A)$, we can add
corresponding symbols to $\Sigma$ and corresponding patterns to $A$ as axioms,
so that, in models, the desired symbols or patterns associated to the
desired operations get interpreted as expected.

For any sorts $s_1,s_2\in S$, assume the following \emph{definedness}
symbol and corresponding pattern:
$$
\begin{array}{l@{\hspace*{7ex}}l}
\lceil\_\rceil_{s_1}^{s_2} \ \ \in \Sigma_{s_1,s_2}
& \mbox{\it // Definedness symbol} \\
\lceil x\!:\! s_1 \rceil_{s_1}^{s_2} \ \ \in A & \mbox{\it // Definedness pattern}
\end{array}
$$
Like in many logics, free variables are assumed universally quantified.
So the definedness pattern axiom above should be read as
``$\forall x\cln s_1\,.\,\lceil x \rceil_{s_1}^{s_2}$''.
If $S$ is infinite, then we have infinitely many definedness symbols and patterns
above.
It is easy to show that if $\varphi \in \Pattern_{s_1}$ then
$\lceil\varphi\rceil_{s_1}^{s_2}$ is a predicate which holds iff $\varphi$ is
defined:
if $\rho : \Var \ra M$ then
$\overline{\rho}(\lceil\varphi\rceil_{s_1}^{s_2})$ is either $\emptyset$
(i.e., $\overline{\rho}(\bot_{s_2})$)
when $\overline{\rho}(\varphi) = \emptyset$
(i.e., $\varphi$ undefined in $\rho$), or is $M_{s_2}$
(i.e., $\overline{\rho}(\top_{s_2})$) 
when $\overline{\rho}(\varphi) \neq \emptyset$ (i.e., $\varphi$ defined).

We also define \emph{totality}, $\lfloor\_\rfloor_{s_1}^{s_2}$, as a derived
construct dual to definedness:
$$
\begin{array}{lcl}
\lfloor\varphi\rfloor_{s_1}^{s_2}
& \equiv &
\neg\lceil\neg\varphi\rceil_{s_1}^{s_2}
\end{array}
$$
Totality also behaves as a predicate.
It states that the enclosed pattern is matched by all values.
That is, if $\varphi \in \Pattern_{s_1}$ then $\lfloor\varphi\rfloor_{s_1}^{s_2}$
is a predicate where if $\rho : \Var \ra M$ is any valuation
then $\overline{\rho}(\lfloor\varphi\rfloor_{s_1}^{s_2})$ is either $\emptyset$
(i.e., $\overline{\rho}(\bot_{s_2})$)
when $\overline{\rho}(\varphi) \neq M_{s_1}$
(i.e., $\varphi$ is not total in $\rho$), or is $M_{s_2}$
(i.e., $\overline{\rho}(\top_{s_2})$) 
when $\overline{\rho}(\varphi) = M_{s_1}$
(i.e., $\varphi$ is total).

\emph{Equality} can be defined quite compactly using pattern totality and
equivalence.
For each pair of sorts $s_1$ (for the compared patterns) and
$s_2$ (for the context in which the equality is used), we define
$\_=_{s_1}^{s_2}\_$ as the following derived construct:
$$
\begin{array}{@{}rcll}
\varphi =_{s_1}^{s_2} \varphi' & \ \ \ \ \ \equiv \ \ \ \ \ &
\lfloor\varphi \lra \varphi'\rfloor_{s_1}^{s_2}
& \ \ \ \ \ \mbox{where } \varphi,\varphi' \in \Pattern_{s_1}
\end{array}
$$
Equality is also a predicate.
if $\varphi,\varphi' \in \Pattern_{s_1}$ and $\rho : \Var \ra M$ then
$\overline{\rho}(\varphi =_{s_1}^{s_2} \varphi') = \emptyset$
iff $\overline{\rho}(\varphi) \neq \overline{\rho}(\varphi')$, and
$\overline{\rho}(\varphi =_{s_1}^{s_2} \varphi') = M_{s_2}$
iff $\overline{\rho}(\varphi) = \overline{\rho}(\varphi')$.

Similarly, we can define \emph{membership}:
if $x\in\Var_{s_1}$, $\varphi\in\Pattern_{s_1}$ and $s_2\in S$, then
let
$$
\begin{array}{@{}rcll}
x \in_{s_1}^{s_2} \varphi & \ \ \ \ \ \equiv \ \ \ \ \ &
\lceil x \wedge \varphi\rceil_{s_1}^{s_2}
& % \ \ \ \ \ \mbox{where } x \in \Var_{s_1},\varphi\in \Pattern_{s_1}\\
\end{array}
$$
Membership is also a predicate.
Specifically, for any $\rho:\Var\ra M$,
$\overline{\rho}(x \in_{s_1}^{s_2} \varphi) = \emptyset$
iff $\rho(x) \not\in \overline{\rho}(\varphi)$, and
$\overline{\rho}(x \in_{s_1}^{s_2} \varphi) = M_{s_2}$
iff $\rho(x) \in \overline{\rho}(\varphi)$.

Since $s_1$ and $s_2$ can usually be inferred from context,
we write $\lceil\_\rceil$ or $\lfloor\_\rfloor$ instead of
$\lceil\_\rceil_{s_1}^{s_2}$ or $\lfloor\_\rfloor_{s_1}^{s_2}$, respectively,
and similarly for the equality and membership.
Also, if the sort decorations cannot be inferred from context, then we assume
the stated property/axiom/rule holds for all such sorts.
\info{Refer to this later when we talk about parameters.}
%
For example, the generic pattern axiom ``$\lceil x \rceil$ where $x\in\Var$''
replaces all the axioms $\lceil x\!:\!s_1 \rceil_{s_1}^{s_2}$ above for all
the definedness symbols for all the sorts $s_1$ and $s_2$.

Note that, by default, symbols are interpreted as relations in matching logic.
It is often the case, though, that we want symbols to be interpreted as
\emph{functions}.
This can be easily done by axiomatically constraining those symbols to evaluate to
singletons.
For example, if $f$ is a unary symbol, then the pattern equation
``$\forall x\,.\,\exists y\,.\,f(x) = y$'' (the convention for free variables
allows us to drop the universal quantifier) states that in any model
$M$, the set $f_M(a)$ contains precisely one element for any $a\in M$.
%
Inspired from similar notations in other logics,
we adopt the familiar notation
``$\sigma : s_1 \times \cdots \times s_n \ra s$''
to indicate that $\sigma$ is a symbol in $\Sigma_{s_1\ldots s_n,s}$ and that
the pattern
$
\exists y\,.\,\sigma(x_1,\ldots,x_n) = y
$ is in $A$.
In this case, we call $\sigma$ a \emph{function symbol} or even just a
\emph{function}.
Patterns built with only function symbols are called
\emph{term patterns}, or simply just \emph{terms}.

\unsure{Should we discuss constructors, too?}

\subsection{Sound and Complete Deduction}
\label{sec:deduction}

Currently, our sound and complete proof system for matching logic extends that
of first-order logic with equality with axioms and proof rules for membership.
In order for this to be feasible, we need equality and membership, which are
available when the definedness symbol is available, as seen in
Section~\ref{sec:useful}.
Therefore, in this section we assume a matching logic theory $(S,\Sigma,A)$
which includes all the definedness symbols discussed in Section~\ref{sec:useful}
(and thus also totality, equality and membership).
We conjecture that it is possible to craft a proof system that does not rely on
the existence of definedness symbols.
Nevertheless, that will not significantly change the \K semantics approach taken
in this paper, because all the existing axioms and proof rules will be proven as
lemmas in the new proof system.
Therefore, any proofs done with the proof system below will be easily translatable
to proofs done with the new proof system, whenever the latter will be available.

\newcommand{\sequent}[2]{{#1}\vdash{#2}}

Our proof system is a Hilbert-style proof system (not to be confused with a
Gentzen-style proof system).
To avoid any confusion about our notation and to remind the reader the
basics of axiom and proof rule \emph{schemas}, we start by briefly recalling
what a Hilbert-style proof system is, but for specificity we do it in the
context of matching logic.
A \emph{proof rule} is a pair $(\{\varphi_1,...,\varphi_n\},\varphi)$,
written
$$
\frac{
\varphi_1 \ \ ... \ \ \varphi_n
}{\varphi}
$$
The formulae $\varphi_1$, ..., $\varphi_n$ are called the \emph{hypotheses}
and $\varphi$ is called the \emph{conclusion} of the rule.
The order in which the hypotheses occur in a proof rule is irrelevant.
When $n = 0$ we call the proof rule an \emph{axiom} and take the freedom to
drop the empty hypotheses and the separating line, writing it simply as
``$\varphi$''.
A proof system allows us to \emph{formally prove} or \emph{derive} formulae.
Specifically, a proof system yields a \emph{provability relation}, written
$\sequent{A}{\varphi}$, for any given specification $(\Sigma,A)$, defined
inductively as follows:
$\sequent{A}{\varphi}$ if $\varphi \in A$; and
$\sequent{A}{\varphi}$ if there is a proof rule like above such that
$\sequent{A}{\varphi_1}$, ..., $\sequent{A}{\varphi_n}$.
Formulae in $A$ can therefore be regarded as axioms, and we even take the
freedom to call them axioms when there is no misunderstanding.
However, note that a proof system is fixed for the target logic, including
all its axioms (i.e., proof rules with no hypotheses).
We use the notation $T \vdashfin \varphi$ or $A \vdashfin \varphi$ to emphasize the fact that the theory $T$ or the set of axioms $A$ is finite.

Proof systems can be and typically are infinite, that is, contain infinitely
many proof rules.
To write them using finite resources (space, time), we make use of \emph{proof schemas}
and \emph{meta-variables}.
As an example, let us recall the usual proof system of propositional logic,
which is also included in the proof system we propose here for matching logic:

\vspace*{2ex}

\noindent
\underline{Propositional calculus proof rules:}

\begin{quote}
1. $\varphi_1 \ra (\varphi_2 \ra \varphi_1)$
\hfill \textsc{(Propositional$_1$)}
\end{quote}

\begin{quote}
2. $(\varphi_1 \ra (\varphi_2 \ra \varphi_3)) \ra ((\varphi_1 \ra \varphi_2) \ra (\varphi_1 \ra \varphi_3))$
\hfill \textsc{(Propositional$_2$)}
\end{quote}

\begin{quote}
3. $(\neg \varphi_1 \ra \neg\varphi_2) \ra (\varphi_2 \ra \varphi_1)$
\hfill \textsc{(Propositional$_3$)}
\end{quote}

\begin{quote}
4. $\displaystyle\frac{\varphi_1 \ \ \ \ \varphi_1 \ra \varphi_2}{\varphi_2}$
\hfill \textsc{(Modus Ponens)}
\end{quote}

In propositional logic, $\varphi_1$, $\varphi_2$ and $\varphi_3$ above are
meta-variables ranging over propositions.
The first three are \emph{axiom schemas} while the fourth is a proper
\emph{rule schema}.
Schemas can be regarded as templates, which specify infinitely many instances,
one for each instance of the meta-variables.
We take the four proof rule schemas of propositional logic unchanged and
regard them as proof rule schemas for matching logic.
Note, however, that the \emph{meta-variables now range over patterns} of
the same sort, and thus there is a schema for each sort.

Matching logic also includes the proof system of first-order logic with
equality.
However, as explained in \cite{rosu-2017-lmcs}, we prefer to replace the
FOL substitution proof rule with two rules, called
\emph{functional substitution}
and \emph{functional variable} below:

\vspace*{2ex}

\noindent
\underline{First-order logic with equality proof rules:}

\begin{quote}
5. $\vdash (\forall x\,.\,\varphi_1\ra\varphi_2) \ra (\varphi_1 \ra \forall x\,.\,\varphi_2)$
when $x\not\in\FV(\varphi_1)$
\hfill \textsc{($\forall$)}
\end{quote}

\begin{quote}
6. $\displaystyle\frac{\varphi}{\forall x\,.\,\varphi}$
\hfill \textsc{(Universal Generalization)}
\end{quote}

\begin{quote}
7. $\vdash (\forall x\,.\,\varphi) \wedge
  (\exists y\,.\,\varphi'=y) \ra \varphi[\varphi'/x]$
\hfill \textsc{(Functional Substitution)}
\improvement{Need to define functional patterns.}
\end{quote}

\begin{quote}
8. $\exists y\,.\,x=y$
\hfill \textsc{(Functional Variable)}
\end{quote}

\begin{quote}
9. $\varphi = \varphi$
\hfill \textsc{(Equality Introduction)}
\end{quote}

\begin{quote}
10. $\varphi_1=\varphi_2 \mathrel\wedge \varphi[\varphi_1/x] \ra \varphi[\varphi_2/x]$
\hfill \textsc{(Equality Elimination)}
\end{quote}

In addition to the above rules borrowed from FOL with equality, matching
logic also introduces the following rules for (reasoning about) membership.

\vspace*{2ex}

\noindent
\underline{Membership rules:}

\begin{quote}
11. $\displaystyle\frac{\varphi}{\forall x\,.\,x\in\varphi}$
\hfill \textsc{(Membership Introduction)}
\end{quote}

\begin{quote}
12. $\displaystyle\frac{\forall x\,.\,x\in\varphi}{\varphi}$
\hfill \textsc{(Membership Elimination)}
\end{quote}

\begin{quote}
13. $x \in y = (x=y)$ when $x,y\in\Var$
\hfill \textsc{(Membership Variable)}
\end{quote}

\begin{quote}
14. $x\in\neg\varphi = \neg(x\in\varphi)$
\hfill \textsc{(Membership $\neg$)}
\end{quote}

\begin{quote}
15. $x\in\varphi_1\wedge\varphi_2 = (x\in\varphi_1) \wedge (x\in\varphi_2)$
\hfill \textsc{(Membership $\wedge$)}
\end{quote}

\begin{quote}
16. $(x\in\exists y\,.\,\varphi) = \exists y\,.\,(x\in\varphi)$ when $x,y\in\Var$ distinct
\hfill \textsc{(Membership $\exists$)}
\end{quote}

\begin{quote}
17. $\begin{array}{l}x\in\sigma(\varphi_1,...,\varphi_{i-1},\varphi_i,\varphi_{i+1},...,\varphi_n) = \\ \exists y\,.\, (y \in\varphi_i \mathrel\wedge x \in\sigma(\varphi_1,...,\varphi_{i-1},y,\varphi_{i+1},...,\varphi_n))\end{array}$
\hfill \textsc{(Membership Symbol)}
\end{quote}

The following result establishes the soundness and completeness
of the proof system above:

\begin{theorem}\cite{rosu-2017-lmcs}
\label{thm:completeness}
For any matching logic specification $(\Sigma,A)$ and $\Sigma$-pattern
$\varphi$, $A \models \varphi$ iff $\sequent{A}{\varphi}$.
\end{theorem}

Note that Theorem~\ref{thm:completeness} also holds when the matching logic
specification is infinite, that is, when it has infinitely many sorts and
symbols in $\Sigma$ and infinitely many axioms in $A$.


\section{Finite Mechanisms to Define Infinite Theories}
\label{sec:finite-mechanisms}

The theoretical results discussed so far imposed no finiteness
restrictions on the sets of sorts, symbols, or patterns that form a matching
logic theory.
In practice, however, like in many other logics or formalisms, we have to
limit ourselves to finitely describable theories.
The simplest approach to achieve that would be to require the theories to be
finite; however, like in many other logics and formalisms, such a requirement
would simply be too strong to be practical.
Instead, we have to adopt or develop conventions, mechanisms and/or languages
that allow us to describe potentially infinite theories using a finite amount
of resources (paper, space, characters, etc.).
For example, many logics allow \emph{axiom schemas} as a way to finitely
define infinite theories.

To prepare the ground for our proposal in Section~\ref{sec:syntax-of-kore},
we here discuss, informally, some ways to finitely describe infinite theories.
Let us start with sorts.
Suppose that we have a finite set of \emph{basic sorts}, such as
$\Nat$, $\Int$, $\Bool$, etc.
Below are several \emph{sort schema} examples that allow us to extend the set
of sorts with infinitely many new sorts:
$$
\begin{array}{rl}
\parametric{\List}{s} &
\textrm{for any sort $s$} \\
\parametric{\Set}{s} &
\textrm{for any sort $s$} \\
\parametric{\Bag}{s} &
\textrm{for any sort $s$} \\
\parametric{\Bag_p}{s} &
\textrm{for any sort $s$ which is not of the form $\parametric{\Bag_p}{\_}$} \\
\parametric{\Map}{s,s'} &
\textrm{for any sorts $s,s'$ \ \ \ // for (partial) maps from keys of sort $s$ to values of sort $s'$} \\
\parametric{\Map_p}{s,s'} &
\textrm{for any sorts $s,s'$ such that $s$ is not of the form $\parametric{\Map_p}{\_,\_}$}
\\
\parametric{\Context}{s,s'} &
\textrm{for any sorts $s,s'$ \ \ \ // for contexts with holes of sort $s$ and results of sort $s'$}
\end{array}
$$
Sort schemas, like all schemas, have a \emph{least fixed-point}
interpretation;
that is, they can be regarded as sort constructors which
{\em inductively define} a (potentially) infinite set of sorts.
The five sort schemas above together with the basic sorts, for example,
generate infinitely many sorts, such as
$\parametric{\List}{\Nat}$,
$\parametric{\Bag}{\parametric{\List}{\Nat}}$,
$\parametric{\Map}{\parametric{\List}{\Int},\parametric{\Set}{\Int}}$,
$\parametric{\Context}{\parametric{\Set}{\Int},\parametric{\Map}{\Int,\Bool}}$,
etc.
Note that sort schemas, like all schemas, can have \emph{side conditions}.
For example, the schema $\parametric{\Bag_p}{s}$ (of \underline{p}roper bags)
disallows instances where $s$ is already a proper bag.
In general, to formally write side conditions over schema parameters we need
access to a \emph{meta-level}.
We will do this in Section~\ref{sec:meta-level}, but for now we will continue
to use side conditions informally.

Let us now move to symbols.
Here are a few \emph{symbol schemas}, defining infinitely many
symbols:\info{Make sure we always use the same symbol for empty sequences of sorts.}
$$
\begin{array}{rl}
\parametric{\nil}{s} \in \Sigma_{*,\parametricscript{\List}{s}} &
\textrm{for any sort $s$} \\
\parametric{\cons}{s} \in \Sigma_{s\times\parametricscript{\List}{s},\parametricscript{\List}{s}} &
\textrm{for any sort $s$} \\
\parametric{\append}{s} \in \Sigma_{\parametricscript{\List}{s}\times\parametricscript{\List}{s},\parametricscript{\List}{s}} &
\textrm{for any sort $s$}
\\[2ex]
\parametric{\emptyMap}{s,s'} \in \Sigma_{*,\parametricscript{\Map}{s,s'}} &
\textrm{for any sorts $s,s'$} \\
\parametric{\bindMap}{s,s'} \in \Sigma_{s\times s',\parametricscript{\Map}{s,s'}} &
\textrm{for any sorts $s,s'$} \\
\parametric{\mergeMap}{s,s'} \in \Sigma_{\parametricscript{\Map}{s,s'}\times \parametricscript{\Map}{s,s'},\parametricscript{\Map}{s,s'}} &
\textrm{for any sorts $s,s'$} \\
\end{array}
$$
And here are some \emph{pattern schemas}, each defining infinitely many patters:
$$
\begin{array}{rl}
\parametric{\append}{s}(\parametric{\nil}{s},l'\cln\parametric{\List}{s})
=_{\parametricscript{\List}{s}}^{s'} l' %\cln\parametric{\List}{s}
& \textrm{for any sorts $s, s'$}
\\[1.5ex]
\begin{array}{@{}l@{}}
\parametric{\append}{s}(\parametric{\cons}{s}(x\cln s,l\cln\parametric{\List}{s}),l'\cln\parametric{\List}{s})
\ =_{\parametricscript{\List}{s}}^{s'} 
\\
\parametric{cons}{s}(x\cln s,\parametric{\append}{s}(
l%\cln\parametric{\List}{s}
,
l'%\cln\parametric{\List}{s}
))
\end{array}
& \textrm{for any sorts $s, s'$}
\\[3.5ex]
\parametric{\mergeMap}{s,s'}(\parametric{\emptyMap}{s,s'},m\cln\parametric{\Map}{s,s'})
=_{\parametricscript{\Map}{s,s'}}^{s''} m %\cln\parametric{\List}{s}
& \textrm{for any sorts $s, s', s''$}
\\[1.5ex]
\begin{array}{@{}l@{}}
\parametric{\mergeMap}{s,s'}(m\cln\parametric{\Map}{s,s'},m'\cln\parametric{\Map}{s,s'})
=_{\parametricscript{\Map}{s,s'}}^{s''}
\\
\parametric{\mergeMap}{s,s'}(m'\cln\parametric{\Map}{s,s'},m\cln\parametric{\Map}{s,s'})
\end{array}
& \textrm{for any sorts $s, s', s''$}
\\[1.5ex]
...
\end{array}
$$

Note that all the sort, symbol and pattern schemas above are parametric in
sorts only.
In theory, they can be parameterized with anything, including with integer
numbers, with symbols, and even with arbitrary patterns.
We found it sufficient in practice to parameterize sort and symbol schemas with
sort parameters only, so for the time being we do not consider any other
parameters for these.
However, pattern schemas sometimes need to be parameterized with symbols and
patterns in addition to sorts.
Consider, for example, the following pattern schema describing the important
property of substitution when applied to a pattern rooted in a symbol:
$$
\begin{array}{rl}
\sigma(\varphi_1,...,\varphi_n)[\varphi/x:s']
=_s^{s''} 
\sigma(\varphi_1[\varphi/x],...,\varphi_n[\varphi/x])
&
\textrm{for any sorts $s, s', s'', s_1,...,s_n$,}
\\
& \textrm{any symbol $\sigma\in\Sigma_{s_1\times...\times s_n, s}$,}
\\
& \textrm{and any pattern $\varphi$ of sort $s$}
\end{array}
$$
The above pattern schema is parametric in sorts, symbols and patterns, and,
of course, has infinitely many instances.

We have seen some simple side conditions in the examples of sort schemas
above.
Pattern schemas, however, tend to have more complex side conditions.
Below are several other common examples of pattern schemas, some of them
with nontrivial side conditions:
$$
\begin{array}{rl}
\varphi[\varphi_1/{x\cln s}] \wedge (\varphi_1 =_s^{s'} \varphi_2) \rightarrow \varphi[\varphi_2/{x\cln s}]
&\textrm{where $s,s'$ are any sorts, $\varphi$ any pattern of} \\
& \textrm{sort $s'$, and $\varphi_1,\varphi_2$ any patterns of sort $s$}
\\[2ex]
\forall x\cln s . \varphi \rightarrow \varphi[t/x]
&\textrm{where $s$ is any sort and $t$ is any \emph{syntactic pattern}, or \emph{term}}, \\
& \textrm{or sort $s$, i.e., one containing only variables and symbols}
\\[2ex]
%(\lambda x . \varphi)\varphi' = \varphi[\varphi'/x]
%& \textrm{where $\varphi$, $\varphi'$ are patterns containing only}
%\\
%& \textrm{variables, $\lambda$ binders and application symbols}
%\\[2ex]
\varphi_1 \mathrel{\texttt{+}} \varphi_2 = \varphi_1 +_\Nat \varphi_2
& \textrm{where $\varphi$, $\varphi'$ are \emph{ground} syntactic patterns of sort $\Nat$,}
\\
&\textrm{that is, patterns built only with symbols \texttt{zero} and \texttt{succ}}
\\[2ex]
(\varphi_1 \rightarrow \varphi_2) \rightarrow
(\varphi[\varphi_1 / x] \rightarrow \varphi[\varphi_2 / x])
& \textrm{where $\varphi$ is a \emph{positive context in $x$}, that is, a pattern}
\\
& \textrm{containing only one occurrence of $x$ with no negation ($\neg$)}
\\
&\textrm{on the path to $x$, and where $\varphi_1$, $\varphi_2$ are any patterns}
\\
&\textrm{having the same sort as $x$}
\end{array}
$$

One of the major goals of this paper is to propose a formal language
and an implementation of it that allow us to finitely specify potentially
infinite matching logic theories presented with finitely many sort, symbol
and pattern schemas.

\section{Important Case Studies}

In this section we illustrate the power of matching logic by showing how it can
handle binders, fixed-points, contexts, and rewriting and reachability.
These important notions or concepts can be defined as syntactic sugar or as
particular theories in matching logic, so that the uniform matching logic proof
system in Section~\ref{sec:deduction} can be used to reason about all of these.
In particular, \K can now be given semantics fully in matching logic.
That is, a \K language definition becomes a matching logic theory, and the
various tools that are part of the \K framework become best-effort
implementations of targeted proof search using the deduction system in
Section~\ref{sec:deduction}.

\subsection{Binders}
\label{sec:binders}

The \K framework allows to define binders, such as the $\lambda$ binder in
$\lambda$-calculus, using the attribute \texttt{binder}.
But what does that really mean?
Matching logic appears to provide no support for binders, except for having
its own binder, the existential quantifier $\exists$.
Here we only discuss untyped $\lambda$-calculus, but the same ideas apply to
any calculus with binders.

Suppose that $S$ consists of only one sort, $\Exp$, for $\lambda$-expressions.
Although matching logic provides an infinite set of variables $\Var_\Exp$ of
sort $\Exp$, we cannot simply define $\lambda\_.\_$ as a symbol in
$\Sigma_{\Var_\Exp \times \Exp, \Exp}$, for at least two reasons:
first, $\Var_\Exp$ is \emph{not} an actual sort at the core level
(as seen in Section~\ref{sec:meta-theory}, it is a sort at the meta-level);
second, we want the first argument of $\lambda\_.\_$ to bind its occurrences
in the second argument, and symbols do not do that.
To ease notation, from here on in this section assume that all variables
are in $\Var_\Exp$ and all patterns have sort $\Exp$.

The key observation here is that the $\lambda\_.\_$ construct in
$\lambda$-calculus \emph{performs two important operations}: on the one hand
it builds a binding of its first argument into its second, and one the other
hand it builds a term.
Fortunately, matching logic allows us to separate these two operations, and
use the builtin existential quantifier for binding.
Specifically, we define a symbol $\lambda^0$ and regard $\lambda$ as syntactic
sugar for the pattern that existentially binds its first argument into $\lambda^0$:
$$
\begin{array}{l}
\lambda^0 \in \Sigma_{\Exp\times\Exp,\Exp} \\
\lambda x . e \equiv \exists x . \lambda^0(x,e)
\end{array}
$$
Therefore, $\lambda^0(x,e)$ builds a term (actually a pattern) with no binding
relationship between the its first argument $x$ and other occurrences of $x$ in
term/pattern $e$, and then the existential quantifier $\exists x$ adds the binding
relationship.\improvement{Explain why $\lambda$ is not a symbol, but an alias}
Mathematically, we can regard $\lambda^0$ as constructing points (input, output)
on the graph of the function, and then the existential quantifier gives us their
union as stated by its matching logic semantics, that is, the actual function.
Note that this same construction does not work in FOL, because there quantifiers
apply to predicates and not to terms/patters.
It is the very nature of matching logic to not distinguish between function
and predicate symbols that makes the above work.
The application can be defined as an ordinary symbol:
$$
\_\,\_ \in \Sigma_{\Exp \times \Exp,\Exp}
$$

Let us now discuss the axiom patterns.
First, note that we get the $\alpha$-equality property,
$$
\lambda x . e = \lambda y . e[y/x]
$$
essentially for free, because matching logic's builtin existential quantifier
and substitution already enjoy the $\alpha$-equivalence
property~\cite{rosu-2017-lmcs}.
The $\beta$-equality, on the other hand, requires an important side condition.
To start the discussion, let us suppose that we naively define it as follows:
$$
\begin{array}{r@{\hspace*{4ex}}l}
(\lambda x . e)e' = e[e'/x]
&
\textrm{for any \emph{pattern} $e$ \ \ \ \ // this is actually wrong!}
\end{array}
$$
The problem is that $e$ and $e'$ cannot be just any arbitrary patterns.
For example, if we pick $e$ to be $\top$ and $e'$ to be $\bot$, then
we can show that $(\lambda x . \top)\bot = \bot$
(see Section~\ref{sec:semantics}: the interpretation of $\_\,\_$ is empty
when any of its arguments is empty), and since $\top[\bot/x] = \top$ we
get $\top = \bot$, that is, inconsistency.
Matching logic, therefore, provides patterns that were not intended for
$\lambda$-calculus.
The solution is to restrict, with side conditions, the application of
$\beta$-equality to only patterns that correspond to $\lambda$-terms
in the original calculus:
$$
\begin{array}{r@{\hspace*{4ex}}l}
(\lambda x . e)e' = e[e'/x]
& \textrm{where $e$, $e'$ are patterns constructed only with variables}
\\
& \textrm{$\lambda$ binders (via desugaring) and application symbols}
\end{array}
$$
That is, we first identify a syntactic fragment of the universe of
patterns which is in a bijective correspondence with the original
syntactic terms of $\lambda$-calculus, and then restrict the
application of the $\beta$-equality rule to only patterns in that 
fragment.

The above gives us an embedding of $\lambda$-calculus as a theory
in matching logic.
We conjecture that this embedding is a \emph{conservative extension},
that is, if $e$ and $e'$ are two $\lambda$-terms, then $e=e'$ holds
in the original $\lambda$-calculus if and only if the corresponding
equality between patterns holds in the matching logic theory.
The ``only if'' part is easy, because equational reasoning is sound
for matching logic~\cite{rosu-2017-lmcs}, but the ``if'' part appears
to be non-trivial.


\subsection{Fixed Points}
\label{sec:fixed-points}

Similarly to the $\lambda$-binder in Section~\ref{sec:binders}, we can
add a fixed-point $\mu$-binder as follows:
$$
\begin{array}{r@{\hspace*{4ex}}l}
\mu^0 \in \Sigma_{\Exp\times\Exp,\Exp}
\\
\mu x . e \equiv \exists x . \mu^0(x,e)
\\
\mu x . e = e[\mu x.e/x]
& \textrm{where $e$ is a pattern corresponding to a term}
\\
& \textrm{in the original calculus (i.e., constructed with variables,}
\\
& \textrm{$\lambda$ and $\mu$ binders (via desugaring), and application symbols}
\end{array}
$$
Given any model $M$ and interpretation $\rho : \Var \ra M$, pattern $e$
yields a function $e_M : M \rightarrow {\cal P}(M)$ where
$e_M(a) = \overline{\rho[a/x]}(e)$.
It is easy to see that its point-wise extension 
$e_M : {\cal P}(M) \rightarrow {\cal P}(M)$ is monotone w.r.t. $\subseteq$,
so by the Knaster-Tarski theorem it has a fixed point\footnote{
Moreover, the set of fixed-points of
$e_M : {\cal P}(M) \rightarrow {\cal P}(M)$ forms a complete lattice.}.
In fact, if we let $X$ be the set $\overline{\rho}(\mu x . e)$, then
the equation of $\mu$ above yields $X = e_M(X)$, that is, $X$ is a fixed point
of $e_M : {\cal P}(M) \rightarrow {\cal P}(M)$.
%
We want, however, $X$ to be the \emph{least} fixed point of $e_M$.
We do not know if that is possible, because $M$ and $\rho$ are arbitrary
and many of the fixed-points of $e_M$ may very well be unreachable with
patterns.
However, from a practical perspective, are those fixed points of any
importance at all?
Considering that when we do proofs we can only derive patterns, it makes
sense to limit ourselves to only fixed points that can be expressed
syntactically.
Within this limited universe, we can axiomatize the
\emph{least fixed-point} nature of $\mu x . e$ with the following
pattern schema:
$$
\begin{array}{r@{\hspace*{4ex}}l}
e[e'/x] = e' \rightarrow \floor{\mu x . e \rightarrow e'}
& \textrm{where $e$ and $e'$ are patterns corresponding to terms}
\\
& \textrm{in the original calculus}
\end{array}
$$

It is now a simple exercise to add a dual, greatest fixed-point construct:
$$
\begin{array}{r@{\hspace*{4ex}}l}
\nu^0 \in \Sigma_{\Exp\times\Exp,\Exp}
\\
\nu x . e \equiv \exists x . \nu^0(x,e)
\\
\nu x . e = e[\nu x.e/x]
& \textrm{where $e$ is a pattern corresponding to a term}
\\
& \textrm{in the original calculus} \\
e[e'/x] = e' \rightarrow \floor{e' \rightarrow \nu x . e}
& \textrm{where $e$ and $e'$ are patterns corresponding to terms}
\\
& \textrm{in the original calculus}
\end{array}
$$

\info{An alternative is to define $\nu x . e$ directly as the dual of
$\mu x . e$, that is, $\nu x . e \equiv \neg \mu x . \neg e$.
Can we prove the pattern above them?}

We extend our conjecture in Section~\ref{sec:binders} and conjecture
that the embedding above, in spite of not necessarily yielding the
expected absolute least fixed-points in all models (but least only
relatively to patterns that can be constructed with the original
syntax), remains a conservative extension: if $e$ and $e'$ are two
terms built with the syntax of the original calculus, then $e=e'$
holds in the original calculus if and only if the corresponding equality holds
in the corresponding matching logic theory.
Like before, the ``only if'' part is easy.

\subsection{Contexts}

Matching logic allows us to define a very general notion of context.
Our contexts can be used not only to define evaluation strategies of
various language constructs, like how evaluation contexts are
traditionally used~\cite{felleisen-hieb-92}, but also for configuration
abstraction to enhance modularity and reuse, and for matching multiple
sub-patterns of interest at the same time.
\unsure{Brandon: how about the locality principle?}

Like $\lambda$ in Section~\ref{sec:binders}, contexts are also defined
as binders.
However, they are defined as schemas parametric in the sorts of their
hole and result, respectively, and their application is controlled by
their structure and surroundings.
We first define the generic infrastructure for contexts:
$$
\begin{array}{r@{\hspace*{5ex}}l}
\parametric{\Context}{s,s'} &
\textrm{sort schema, where $s$ (hole sort) and}
\\ &\textrm{$s'$ (result sort) range over any sorts}
\\ \parametric{\gamma^0}{s,s'} \in \Sigma_{s \times s', \parametricscript{\Context}{s,s'}}
& \textrm{symbol schema, for all sorts $s, s'$}
\\ \parametric{\gamma\_.\_}{s,s'}(\hole\cln s,T\cln s') \equiv \exists \hole . \parametric{\gamma^0}{s,s'}(\hole,T)
& \textrm{here, $\hole$ is an ordinary variable}
\\
\parametric{\_[\_]}{s,s'} \in \Sigma_{\parametricscript{\Context}{s,s'} \times s, s'}
& \textrm{symbol schema, for all sorts $s, s'$}
\\
\parametric{\_[\_]}{s,s}(\parametric{\gamma\_.\_}{s,s}(\hole\cln s, \hole),T\cln s) = T
& \textrm{axiom schema for identity contexts, for all sorts $s$}
\end{array}
$$
The sort parameters of axiom schemas can usually be inferred from the context.
To ease notation, from here on we assume they can be inferred and apply the
mixfix notation for symbols containing ``$\_$'' in their names.
With these, the last axiom schema above becomes:
$$
(\gamma \hole .\; \hole)[T] = T
$$

The above sort, symbol and axiom schemas are generic and tacitly assumed in
all definitions that make use of contexts.
Let us now illustrate specific uses of contexts.

\subsubsection{Evaluation Strategies of Language Constructs}

Suppose that a programming language has an if-then-else statement,
say $\ite\in\Sigma_{\BExp\times\Stmt\times\Stmt,\Stmt}$,
whose evaluation strategy is to first evaluate its first argument and then, depending
on whether it evaluates to $\ttrue$ or $\ffalse$, to rewrite to either
its second argument or its third argument.
We here only focus on its evaluation strategy and not its reduction rules;
the latter will be discussed in Section~\ref{sec:rewriting}.
Assuming that all reductions/rewrites apply in context, as discussed in
Section~\ref{sec:rewriting}, we can state that $\ite$ is given permission to
apply reductions within its first argument with the following axiom:
$$
\ite(C[T],S_1,S_2) = (\gamma\hole.\;\ite(C[\hole],S_1,S_2))[T]
$$
In particular, $C$ can be the identity context, ``$\gamma \hole .\; \hole$''.
In addition to sort/parameter inference, front-ends of implementations of
matching logic are expected to provide shortcuts for such rather boring
axioms.
For example, \K provides the \textsf{strict} attribute to be used with symbol
declarations for exactly this purpose; for example, the evaluation strategy
of $\ite$, or the axiom above, is defined with the attribute
\textsf{strict(1)} associated to the declaration of the symbol $\ite$.

As an example, suppose that besides $\ite$ with strategy \textsf{strict(1)}
we also have an infix operation $\_<\_\in\Sigma_{\AExp\times\AExp,\BExp}$ with
strategy \textsf{strict(1,2)}
(i.e., it has two axioms like above, corresponding to each of its two
arguments).
Using these axioms, we can infer the following:
$$
\begin{array}{rcll}
\ite(1 < x,S_1,S_2) & = &
\ite(1 < (\gamma\hole.\;\hole)[x],S_1,S_2)
& \textrm{// context identity}
\\
& = &
\ite((\gamma\hole.\;1 < \hole)[x],S_1,S_2)
& \textrm{// \textsf{strict(2)} axiom for $\_<\_$}
\\
& = &
(\gamma\hole.\;\ite(1 < \hole,S_1,S_2))[x]
& \textrm{// \textsf{strict(1)} axiom for $\ite$ above}
\end{array}
$$
Therefore, $\ite(1 < x,S_1,S_2)$ can be matched against a pattern
of the form $C[x]$, where $C$ is a context of sort
$\parametric{\Context}{\AExp,\Stmt}$.
That is, $x$ has been ``pulled'' out of the $\ite$ context;
now other semantic rules or axioms can be applied to reduce $x$, by
simply matching $x$ in a context.
At any moment during the reduction, the axioms above can be applied
backwards and thus whatever $x$ reduces to can be ``plugged'' back into
its context.
This way, the axiomatic approach to contexts in matching logic
achieves the ``pull and plug'' mechanism underlying reduction
semantics with evaluation contexts~\cite{felleisen-hieb-92} by
means of logical deduction using the generic sound and complete
proof system in Section~\ref{sec:deduction}.
Also, notice that our notion of context is more general than
that in reduction semantics.
That is, it is not only used for reduction or in order to isolate
a redex to be reduced, but it can be used for matching any relevant
data from a program configuration.
More examples below will illustrate that.

\subsubsection{Nested Contexts}

Nesting of contexts comes for free in our approach, that is, nothing but
reasoning using the deduction system of matching logic needs to be done
in order to achieve matching with nested contexts.
For example:
$$
\begin{array}{rcll}
\ite(1 < x,S_1,S_2) & = &
\ite((\gamma\hole.\;\hole)[1 < x],S_1,S_2)
& \textrm{// context identity}
\\
& = &
(\gamma\hole.\;\ite(\hole,S_1,S_2))[1 < x]
& \textrm{// \textsf{strict(1)} axiom for $\ite$}
\\
& = &
(\gamma\hole.\;\ite(\hole,S_1,S_2))[(\gamma\hole.\;1 < \hole)[x]]
& \textrm{// \textsf{strict(2)} axiom for $\_<\_$}
\end{array}
$$
Therefore, $\ite(1 < x,S_1,S_2)$ can also be matched against a pattern
of the form $C_1[C_2[x]]$, where $C_1$ is a context of sort
$\parametric{\Context}{\BExp,\Stmt}$ and $C_2$ of sort
$\parametric{\Context}{\AExp,\BExp}$.
More interestingly,
$$
\begin{array}{rcll}
\ite(1 < x,S_1,S_2) & = &
\ite(1 < (\gamma\hole.\;\hole)[x],S_1,S_2)
& \textrm{// context identity}
\\
& = &
\ite((\gamma\hole.\;1 < \hole)[x],S_1,S_2)
& \textrm{// \textsf{strict(2)} axiom for $\_<\_$}
\\
& = &
(\gamma\hole.\;\ite(1 < \hole,S_1,S_2))[x]
& \textrm{// \textsf{strict(1)} axiom for $\ite$}
\\
& = &
(\gamma\hole.\;\ite((\gamma\hole.\;\hole)[1 < \hole],S_1,S_2))[x]
& \textrm{// context identity}
\\
& = &
(\gamma\hole.\;(\gamma\hole.\;\ite(\hole,S_1,S_2))[1 < \hole])[x]
& \textrm{// \textsf{strict(1)} axiom for $\ite$}
\end{array}
$$
Therefore, $\ite(1 < x,S_1,S_2)$ can also be matched against a pattern
of the form ($\gamma\hole.\;C_1[T_2])[x]$, where $C_1$ is a context of
sort $\parametric{\Context}{\BExp,\Stmt}$ and $C_2 = \gamma\hole.\;T_2$ is
a context of sort $\parametric{\Context}{\AExp,\BExp}$.
Notice that we cannot naively apply a context to another context, e.g.,
$C_1[C2]$, because the sorts do not match.
Once the hole is explicitly mentioned as a binder in a context, what we really
mean by $C_1[C2]$ is in fact $\gamma\hole.\;C_1[T_2]$, where
$C_2 = \gamma\hole.\;T_2$.


\subsubsection{Multi-Hole Contexts and Configuration Abstraction}

Contexts with multiple holes can also be easily supported by our approach,
also without anything extra but the already existing deductive system of
matching logic.
A notation for multi-hole context application, however, is recommended in
order to make patterns easier to read. Specifically,
$$
(\gamma \hole_1 \hole_2 \dots \hole_n . \; T)[T_1,T_2,\dots,T_n]
\equiv (\gamma \hole_n .\; \dots (\gamma\hole_2.\;(\gamma\hole_1.\;T)[T_1])[T_2]\dots)[T_n]
$$
Although $\gamma \hole_1 \hole_2 \dots \hole_n . \; T$ correspond to no
patterns, we take a freedom to call them \emph{multi-hole contexts} and
let meta-variables $C$ range over them, i.e., we take the freedom to write
$C[T_1,T_2,\dots,T_n]$.
We believe multi-hole contexts can be formalized as patterns, but we have
not found any need for it yet.

Multi-hole contexts are particularly useful to define abstractions over
program configurations.
Indeed, \K provides and promotes \emph{configuration abstraction} as a
mechanism to allow compact and modular language semantic definitions.
The idea is to allow users to only write the parts of the program
configuration that are necessary in semantic rules, the rest of the
configuration being inferred automatically.
This configuration abstracton process that is a crucial and distinctive
feature of \K can be now elegantly explained with multi-hole contexts.

To make the discussion concrete, suppose that we have a program configuration
(\textsf{cfg}) that contains the code (\textsf{k}), the environment
(\textsf{env}) mapping program variables to locations,
and a memory (\textsf{mem}) mapping locations to values.
For example, the term/pattern
$$
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ \textsf{mem}(l \mapsto a, R_\textit{mem})
)
$$
denotes a configuration containing the program
``$\ite(1 < x,S_1,S_2)\textsf{;\ }S_3$''
that starts with an $\ite$ statement followed by the rest of the program $S_3$,
the environment ``$x \mapsto l, R_\textit{env}$'' holding a binding
of $x$ to location $l$ and the rest of the bindings $R_\textit{env}$,
and the memory ``$l \mapsto a, R_\textit{mem}$'' holding a binding
of $l$ to value $a$ and the rest of the bindings $R_\textit{mem}$.
In \K, in order to replace $x$ in the program above with its value $a$ by
applying the lookup semantic rule, we need to match the configuration above
against the pattern $C[x,x\mapsto l,l\mapsto a]$, where $C$ is a multi-hole
context.
First, like we did with the strictness axiom of $\ite$, we need to give
contextual matching permission to operate in the various places of the
configuration where we want to match patterns in context.
In our case, we do that everywhere:
$$
\begin{array}{l}
\textsf{cfg}(C[T],E,M) = (\gamma\hole.\;\textsf{cfg}(C[\hole],E,M))[T]
\\
\textsf{cfg}(K,C[T],M) = (\gamma\hole.\;\textsf{cfg}(K,C[\hole],M))[T]
\\
\textsf{cfg}(K,E,C[T]) = (\gamma\hole.\;\textsf{cfg}(K,E,C[\hole]))[T]
\\
\textsf{k}(C[T]) = (\gamma\hole.\;\textsf{k}(\hole))[T]
\\
\textsf{env}(C[T]) = (\gamma\hole.\;\textsf{env}(\hole))[T]
\\
\textsf{mem}(C[T]) = (\gamma\hole.\;\textsf{mem}(\hole))[T]
\end{array}
$$
Additionally, we also give permission for contextual matchings to
take place in maps, which are regarded as patterns built with
the infix pairing construct ``$\_\mapsto\_$'' and an associative and
commutative merge operation, here denoted as a comma ``$\_,\_$'', which
has additional properties which are not relevant here:
$$
(C[M_1],M_2) = (\gamma\hole.\;(\hole,M_2))[M_1]
$$
The following matching logic proof shows how the configuration above
can be transformed so that it can be matched by a multi-hole context
as discussed:

$$
\begin{array}{@{}rcl}
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ \textsf{mem}(l \mapsto a, R_\textit{mem})
)
&=&
\\
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ \textsf{mem}((\gamma\hole_3.\;\hole_3)[l \mapsto a], R_\textit{mem})
)
&=&
\\
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ \textsf{mem}((\gamma\hole_3.\;(\hole_3,R_\textit{mem}))[l \mapsto a])
)
&=&
\\
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ (\gamma\hole_3.\;\textsf{mem}(\hole_3,R_\textit{mem}))[l \mapsto a]
)
&=&
\\
(\gamma\hole_3.\;\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(x \mapsto l, R_\textit{env})
,
\ \textsf{mem}(\hole_3,R_\textit{mem})))[l \mapsto a]
&=&
\\
...
&=&
\\
(\gamma\hole_3.\;
(\gamma\hole_2.\;
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(\hole_2, R_\textit{env})
,
\ \textsf{mem}(\hole_3,R_\textit{mem})))[x \mapsto l])[l \mapsto a]
&=&
\\
(\gamma\hole_2\hole_3.\;
\textsf{cfg}
(
\textsf{k}(\ite(1 < x,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(\hole_2, R_\textit{env})
,
\ \textsf{mem}(\hole_3,R_\textit{mem})))[x \mapsto l,l \mapsto a]
&=&
\\
...
&=&
\\
(\gamma\hole_2\hole_3.\;
(\gamma\hole_1.\;
\textsf{cfg}
(
\textsf{k}(\ite(1 < \hole_1,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(\hole_2, R_\textit{env})
,
\ \textsf{mem}(\hole_3,R_\textit{mem})))[x]
)[x \mapsto l,l \mapsto a]
&=&
\\
(\gamma\hole_1\hole_2\hole_3.\;
\textsf{cfg}
(
\textsf{k}(\ite(1 < \hole_1,S_1,S_2)\textsf{;\ }S_3),
\ \textsf{env}(\hole_2, R_\textit{env})
,
\ \textsf{mem}(\hole_3, R_\textit{mem})
))
[x, x \mapsto l, l \mapsto a]
\end{array}
$$


\subsection{Rewriting and Reachability}
\label{sec:rewriting}

Matching logic patterns generalize terms: indeed, each term $t$ is a
particular pattern built only with variables and symbols.
Furthermore, reachability rules in reachability
logic~\cite{rosu-stefanescu-ciobaca-moore-2013-lics,stefanescu-ciobaca-mereuta-moore-serbanuta-rosu-2014-rta},
which have the form $\varphi \Rightarrow \varphi'$ where $\varphi$ and $\varphi'$
are patterns of the same sort, generalize rewrite rules.
A set of reachability rules $\cal S$, for example a \K language
definition, yields a binary relation $\_\ra_{\cal S}\_ \subseteq M \times M$
on any given model $M$, called a \emph{transition system}.
The transition system $(M,\ra_{\cal S})$ is a mathematical model of $\cal S$,
comprising all the dynamic behaviors of $\cal S$.
Reachability logic consists of a proof system for reachability rules,
which is sound and relatively complete.
Until now, \K's semantics was best explained in terms of reachability logic.
However, it turns out that matching logic is expressive enough to represent
both rewriting and reachability.
Together with the other results above, this implies that matching
logic can serve as a standalone semantic foundation of~$\K$.

Let us first note that, in matching logic, giving a binary relation
$R_s \in M_s \times M_s$ on the carrier of sort $s$ of a model $M$
is equivalent to interpreting a unary symbol $\circ \in \Sigma_{s,s}$ in $M$:
indeed, for any $a,b\in M_s$, take $a\mathrel{R_s} b$ iff $a \in \circ_M(b)$.
If the intuition for $a \mathrel{R_s} b$ is ``state $a$ transitions to
state $b$'', then the intuition for $\circ_M$ is that of ``transition to''
or ``next'':
$\circ_M(b)$ is the set of states that transition to $b$, or which next go
to $b$.
Next consider two patterns $\varphi$ and $\varphi'$ of sort $s$, and the
pattern $\varphi \ra \circ \varphi'$.
We have $M \models \varphi \ra \circ \varphi'$ iff
$\overline{\rho}(\varphi) \subseteq \circ_M(\overline{\rho}(\varphi'))$
for any $M$-valuation $\rho$, iff for any $a\in\overline{\rho}(\varphi)$
there is some $b \in \overline{\rho}(\varphi')$ such that $a\mathrel{R_s}b$,
which is precisely the interpretation of a rewrite rule
$\varphi \Rightarrow \varphi'$ in $M$.
Consequently, we can add multi-sorted rewriting to a matching logic theory
as follows:
$$
\begin{array}{r@{\hspace*{7ex}}l}
\parametric{\circ}{s} \in \Sigma_{s,s}
& \textrm{// a ``next'' symbol schema}
\\
\varphi\mathrel{\parametric{\Rightarrow}{s}}\varphi'
\equiv \varphi \rightarrow \parametric{\circ}{s} \varphi'
& \textrm{// a ``rewrite relation'' alias schema}
\end{array}
$$
To avoid clutter, we write $\Rightarrow$ instead of
$\parametric{\Rightarrow}{s}$ and assume that $s$ can be inferred from
context.

rules apply in contexts by default
as implication and as fixed-points 


\section{Built-ins}
\label{sec:builtins}

It is rarely the case in practice that a matching logic theory, for example
a programming language semantics, is defined from scratch.
Typically, it makes use of built-ins, such as natural/integer/real numbers.
While sometimes builtins can be defined themselves as matching logic theories,
for example Booleans, in general such definitions may require sets of axioms
which are not r.e., and thus may be hard or impossible to encode regardless
of the chosen formalism.
Additionally, different tools may need to regard or use the builtins
differently;
for example, an interpreter may prefer the builtins to be hooked to a
fast implementation as a library, a symbolic execution engine may prefer the
builtins to be hooked to an SMT solver like Z3, while a mechanical program
verifier may prefer a rigorous definition of builtins using Coq, Isabelle,
or Agda.

Recall from Section~\ref{sec:semantics} that the semantics of a matching
logic theory $(\Sigma,A)$ was loosely defined as the collection of all
$\Sigma$-models satisfying its axioms: $\denote{(\Sigma,A)} =
\{M \ \mid \ M \in \Mod_{\Sigma},\ M \models_{\Sigma} A \}$.
To allow all the builtin scenarios above and stay as abstract as possible
w.r.t.~builtins, we generalize matching logic theories and their semantics
as follows.

\begin{definition}
A \emph{matching logic theory with builtins}
$(S_\builtin,\Sigma_\builtin,S,\Sigma,A)$, written as a triple
$(\Sigma_\builtin,\Sigma,A)$ and
called just a \emph{matching logic theory} whenever there is no confusion,
is an ordinary matching logic theory together with a
\emph{subsignature of builtins}
$(S_\builtin,\Sigma_\builtin)\hookrightarrow(S,\Sigma)$.
Sorts in $S_\builtin \subseteq S$ are called \emph{builtin sorts} and symbols in
$\Sigma_\builtin \subseteq \Sigma$ are called \emph{builtin symbols}.
\end{definition}

Therefore, signatures identify a subset of sorts and symbols as builtin,
with the intuition that implementations are now \emph{parametric} in an
implementation of their builtins.
Or put differently, the semantics of a matching logic theory with builtins
is parametric in a model for its builtins:

\begin{definition}
Given a matching logic theory with builtins $(\Sigma_\builtin,\Sigma,A)$ and
a \emph{model of builtins} $B \in \Mod(\Sigma_\builtin)$, we define
the \emph{$B$-semantics} of $(\Sigma_\builtin,\Sigma,A)$ loosely as follows:
$$
\denote{(\Sigma_\builtin,\Sigma,A)}_B = 
\{M \ \mid \ M \in \Mod_{\Sigma},\ M \models_{\Sigma} A,\ \reduct{M}{\Sigma_\builtin} = B \}
$$
We may drop $B$ from $B$-semantics whenever the builtins model is
understood from context.
\end{definition}

Note that $A$ may contain axioms over $\Sigma_\builtin$, which play a dual
role: they filter out the candidates for the models of builtins on the one
hand, and they can be used in reasoning on the other hand\info{For this,
we may want to organize ML as an institution.}.
Theoretically, we can always enrich $A$ with the set of \emph{all} patterns
matched by $B$, and thus all the properties of the model of builtins are
available for reasoning in any context, but note that in practice there may
be no finite or algorithmic way to represent those
(e.g., the set of properties of the ``builtin'' model of natural numbers is
not r.e.).

\section{The Meta-Theory: A Reflection in Matching Logic}
\label{sec:meta-theory-reflection}

This section is a follow-up to Section~\cref{sec:finite-mechanisms}, in which 
we introduced various \emph{schema mechanisms} that allow us to define infinite 
theories using a finite amount of resources.
In this and the next few sections, we give such schema mechanisms \emph{a 
formal meaning} by axiomatizing them as a matching logic theory: the 
meta-theory $K$.
We are going to define the meta-theory $K$ in detail in 
Section~\cref{sec:meta-theory}, while before that, we would like to
illustrate the big picture first and point out the relationship between our work
and the studies of \emph{reflection in logic}.



%Consider a matching logic prover $P$ that decides whether a matching logic 
%patter $\varphi$ holds in a matching logic theory $T$. 
%
%The prover $P$ is an executable program written in some programming language, 
%and it has two inputs: a piece of data that \emph{encodes} the pattern 
%$\varphi$, and another piece of data that \emph{encodes} the theory $T$.
%With the sound and complete proof system of matching logic that is introduced 
%in~\cite{rosu-2017-lmcs}, we expect the prover $P$ to be a semi-decision 
%procedure---that is, $P$ always halts with success if $T \vdash \varphi$ and 
%either halts with failure or never halts if $T \not\vdash \varphi$.
%
%The main focus in this and the next two sections is not about \emph{how to 
%design and implement the prover $P$}, but about \emph{how to encode $\varphi$ 
%and $T$ as data that can be fed into $P$ as inputs}.
%In other words, we are interested in \emph{representations} of patterns and 
%matching logic theories.
%Since any executable programs (in the normal sense) can only handle finite 
%inputs, we are in particular interested in \emph{finite representations} of 
%patterns and matching logic theories.

Reflection in logic and programming languages has been extensively studied 
in literature.
We here quote a rather broad definition by Brian Smith, who in~\cite{smith-1984-popl} defines 
reflection as
\begin{displayquote}
	an entity’s integral ability to represent, operate on,
	and otherwise deal with its self in the same way that
	it represents, operates on and deals with its primary
	subject matter.
\end{displayquote}
Following this definition, the meta-theory $K$ is said to be a {reflective} one 
because 
(1) $K$ itself is a matching logic theory and 
(2) one can use $K$ to study and discuss the properties of matching logic and 
matching logic theories, as shown in the next theorem (the faithfulness 
theorem):
\begin{center}
	\begin{tabular}{cc}
		$
		\prftree[r]{\footnotesize (Upward Reflection)}
		{T \vdash \varphi}
		{K \cup \denote{T} \vdashfin \Kdeduce(\denote{\varphi})}
		$
		&
		$
		\prftree[r]{\footnotesize (Downward Reflection)}
		{K \cup \denote{T} \vdashfin \Kdeduce(\denote{\varphi})}
		{T \vdash \varphi}
		$
	\end{tabular}
\end{center}
where 
\begin{itemize}
	\item $\denote{T}$, called the \emph{meta-representation of $T$}, consists of a finite number of new symbols and axioms depending on $T$;
	\item $K \cup \denote{T}$, called the \emph{meta-theory instantiated by $T$}, is the meta-theory $K$ plus the finitely many symbols and axioms in $\denote{T}$;
	\item $\denote{\varphi}$ is the \emph{meta-representation of $\varphi$} as a matching logic pattern in $K \cup \denote{T}$;
	\item $\Kdeduce$ is a symbol in $K$ which axiomatizes the probability relation in matching logic (see Section~\cref{sec:ML-proof-system})
\end{itemize}

The double bracket $\denote{\_}$ is called \emph{lifting}, which brings objects to their meta-representations in the meta-theory $K$.
Lifting will be defined in detail in Section~\cref{sec:reflect}, after we present in full length the meta-theory $K$ in Secion~\cref{sec:meta-theory}

\section{Meta-Theory of Matching Logic}
\label{sec:meta-theory}

In this section, we present a finite matching logic theory $K = ( S_K, \Sigma_K, F_K )$ as \emph{the meta-theory of matching logic}.
$K$ is a finite theory and has $S_K$ , $\Sigma_K$, and $F_K$ being its finite sets of sorts, symbols, and axioms, respectively.
We are going to define the meta-theory $K$ in detail in the following subsections.
A summary is provided in Section~\cref{sec:K-summary}.

\subsection{Truth}

A sort $\KPred$ is introduced to capture predicates and the predicate logic.
Patterns of sort $\KPred$ are called \emph{predicate patterns} or just \emph{predicates}, and symbols whose return sort are $\KPred$ are called \emph{predicate symbols}. 
Predicate symbols in $\Kfinite$ are defined in later sections when they firstly appear.
\begin{notation}
	If $b$ is a predicate pattern, we take the freedom to write $b$ instead of $b = \top_\KPred$, so that $\KPred$ patterns can be used in any sort context.
\end{notation}

\subsection{Characters and Strings}
\label{sec:chars-string}
The sort $\KChar$ is the sort for \emph{characters}. It has the following $26 + 26 + 10 = 62$ functional symbols as constructors:
\begin{center}
	\begin{tabular}{c c c}
		$\quot{a} \colon \to \KChar$ & $\quot{b} \colon \to \KChar$ & $\quot{c} \colon \to \KChar$ \\
		$\cdots$ & $\cdots$ & $\cdots$ \\
		$\quot{x} \colon \to \KChar$ & $\quot{y} \colon \to \KChar$ & $\quot{z} \colon \to \KChar$ \\
		$\quot{A} \colon \to \KChar$ & $\quot{B} \colon \to \KChar$ & $\quot{C} \colon \to \KChar$ \\
		$\cdots$ & $\cdots$ & $\cdots$ \\
		$\quot{X} \colon \to \KChar$ & $\quot{Y} \colon \to \KChar$ & $\quot{Z} \colon \to \KChar$ \\
		$\quot{0} \colon \to \KChar$ & $\cdots$ & $\quot{9} \colon \to \KChar$ 
	\end{tabular}
\end{center}

\paragraph{String as Finite Lists of Characters.}\quad
Characters are used to construct \emph{strings}, which will be formalized as finite lists of characters.
In Section~\cref{sec:finite-lists}, we will define a sort $\KCharList$ for finites lists of characters, and two functional constructors
\begin{align*}
 & \KnilKCharList \colon \to \KCharList \\
 & \KconsKCharList \colon \KChar \times \KCharList \to \KCharList
\end{align*}
that construct lists of characters.

\begin{notation}
	We write $\KString$ as an alias of the sort $\KCharList$, and we write $\Kepsilon$ as an alias of $\KnilKCharList$ which represents the empty string.
\end{notation}

\begin{notation}
	As a convention, strings are often represented by texts wrapped with quotation marks. 
	For example, instead of writing
	$$
	\KconsKCharList(\quot{a}, \KconsKCharList(\quot{b}, \KconsKCharList(\quot{c}, \Kepsilon)))
	$$
	we simply write $\quot{abc}$.
\end{notation}

\subsection{Matching Logic Sorts and Symbols}
\label{sec:ML-sorts-symbols}

The sort $\KSort$ is the sort for matching logic sorts.
The only constructor of the sort $\KSort$ is the functional symbol
$$
\Ksort \colon \KString \times \KSortList \to \KSort
$$
which takes a \emph{name} and a list of \emph{sort parameters}. 

The sort $\KSymbol$ is the sort for matching logic symbols.
The only constructor of the sort $\KSymbol$ is the functional symbol
\begin{equation*}
\Ksymbol \colon \KString \times \KSortList\footnote{The sort $\KSortList$ is defined in Section~\cref{sec:finite-lists}} \times \KSort \times \KSortList \to 
\KSymbol \times \KSort \to \KSymbol
\end{equation*}
where the first argument is called the \emph{name} of the symbol, and the rest arguments are called the \emph{argument sorts} and the \emph{return sort} of the symbol. 
Two getter functions, $\KgetArgumentSorts$ and $\KgetReturnSort$, are defined as functional symbols
\begin{align*}
 & \KgetArgumentSorts \colon \KSymbol \to \KSortList \\
 & \KgetReturnSort    \colon \KSymbol \to \KSort
\end{align*}
with axioms
\begin{align*}
 & \KgetArgumentSorts(\Ksymbol(f, S, s)) = S\\
 & \KgetReturnSort(\Ksymbol(f, S, s)) = s
\end{align*}
where $f$ is a $\KString$ variable, $S$ is a $\KSortList$ variable, and $s$ is 
a $\KSort$ variable.

\paragraph{Definedness Symbols}
Definedness symbols are required for the sound and complete proof system of 
matching logic that is introduced in~\cite{rosu-2017-lmcs}.
For any matching logic theory and two sorts $s, s'$ in the theory, we assume 
there exists a symbol $\ceil{\_}_s^{s'}$ with the axiom $\ceil{x \cln 
s}_s^{s'}$ defined in the theory.

In the meta-theory of matching logic $\Kfinite$, the symbol $\KSymbolceil$ is 
the 
symbol for the definedness symbols
\begin{equation*}
  \KSymbolceil \colon \KSort \times \KSort \to \KSymbol
\end{equation*}
with the axiom
\begin{equation*}
  \KSymbolceil(s, s') = \Ksymbol(\text{``ceil''}, (s), s')
\end{equation*}
where $(s)$ is the singleton list that consists of only one sort $s$ (see 
Notation~\ref{notation:lists}).

\subsection{Finite Lists}
\label{sec:finite-lists}

For sorts $\KChar$, $\KSort$, $\KSymbol$, $\KVariable$, and 
$\KPattern$\footnote{The sort $\KPattern$ is defined in 
Section~\cref{sec:matching-logic-patterns}.}
in $S_\Kfinite$,
we define sorts $\KCharList$, $\KSortList$, $\KSymbolList$, and $\KPatternList$ to be the sorts of finite lists over them, respectively.
Formally, for any sort $X$ where
$$
X \in \{\KChar, \KSort, \KSymbol, \KPattern\}
$$
the sort $\XList$ is in $S_\Kfinite$, and the following functional constructors of the sort $\XList$ are in $\Sigma_\Kfinite$
\begin{align*}
  & \KnilXList \colon \to \XList
  \\
  & \KconsXList \colon \mathit{X} \times \XList \to \XList
\end{align*}

\begin{notation}
\label{notation:lists}
	To write lists expression more compactly, we adopt the following abbreviations
	\begin{equation*}
	  (x_1, x_2, \dots, x_n) \equiv \KconsXList(x_1, \KconsXList(x_2, \dots\KconsXList(x_n, \KnilXList)\dots))
	\end{equation*}
\end{notation}

Common operations on lists can be defined as functional symbols on $\XList$.
The symbol $$\KappendXList \colon \XList \times \XList \to \XList$$ 
takes two lists and returns the concatenation of them, with two axioms
\begin{align*}
  & \KappendXList(\KnilXList, L) = L
  \\
  & \KappendXList(\KconsXList(x, L_0), L) = \KconsXList(x, \KappendXList(L_0, L))
\end{align*}

The predicate symbol $$\KinXList \colon \mathit{X} \times \XList \to \KPred$$
takes an element and a list, and decides whether the element is a member of the 
list or not. The two axioms for $\KinXList$ are
\begin{align*}
  & \neg \KinXList(x, \KnilXList)
  \\
  & \KinXList(x, \KconsXList(y, L)) = (x = y) \vee \KinXList(x, L)
\end{align*}

The functional symbol $$\KdeleteXList \colon \mathit{X} \times \XList \to \XList$$
takes an element and a list, and returns the list in which all the occurrences
of the element have been deleted, and the order of the remaining elements does not
change.
It is axiomatized by the next two axioms
\begin{align*}
  & \KdeleteXList(x, \KnilXList) = \KnilXList
  \\
  & \KdeleteXList(x, \KconsXList(y, L))
  \\
  & = ((x = y) \wedge \KdeleteXList(x, L)) \vee ((x \neq y) \wedge \KconsXList(y, \KdeleteXList(x, L)))
\end{align*}


\subsection{Matching Logic Patterns}
\label{sec:ML-patterns}

\paragraph{Matching Logic Variables.}
The sort $\KVariable$ is the sort for 
matching logic variables, with the only functional constructor
\begin{equation*}
  \Kvariable \colon \KString \times \KSort \to \KVariable
\end{equation*}
in which the first argument is called the $\emph{name}$ of the variable, while 
the second argument is the sort of the variable.

\paragraph{Matching Logic Patterns.}
The sort $\KPattern$ is the sort for matching logic patterns.
It has in total five functional constructors, including the following four 
symbols
\begin{align*}
  & \Kapplication \colon \KSymbol \times \KPatternList \to \KPattern
  \\
  & \Kand \colon \KSort \times \KPattern \times \KPattern \to \KPattern
  \\
  & \Knot \colon \KSort \times \KPattern \to \KPattern
  \\
  & \Kexists \colon \KSort \times \KVariable \times \KPattern \to \KPattern
\end{align*}
and an injection function from sort $\KVariable$ to sort $\KPattern$
\begin{equation*}
  \KVariableToKPattern \colon \KVariable \to \KPattern
\end{equation*}


Apart from the five constructor symbols, the sort $\KPattern$ also has
the following functional symbols for derived logic connectives
\begin{align*}
  & \Kor \colon \KSort\times\KPattern \times \KPattern   \to \KPattern
  \\
  & \Kimplies \colon \KSort\times\KPattern \times \KPattern   \to \KPattern
  \\
  & \Kiff \colon \KSort\times\KPattern \times \KPattern   \to \KPattern
  \\
  & \Kforall \colon \KSort\times\KVariable \times \KPattern   \to \KPattern
  \\
  & \Kceil \colon \KSort\times\KSort\times\KPattern     \to \KPattern
  \\
  & \Kfloor \colon \KSort\times\KSort\times\KPattern     \to \KPattern
  \\
  & \Kequals \colon \KSort\times\KSort \times \KPattern \times \KPattern \to 
  \KPattern
  \\
  & \Kmembership \colon \KSort \times \KSort \times \KVariable \times 
  \KPattern  \to \KPattern
  \\
  & \Ktop \colon \KSort \to \KPattern
  \\
  & \Kbottom \colon \KSort \to \KPattern
\end{align*}



\begin{notation}\label{notation:variables-about-KPattern}
	As a convention, we use $\varphi$ and $\psi$ for $\KPattern$ variables, 
	$x$, $y$, and $z$ for $\KString$ variables, $s$ for $\KSort$ variables, $v, 
	u$ for $\KVariable$ variables, and $\sigma$ for $\KSymbol$ variables. 
\end{notation}

Derived logic connectives are axiomatized by the following axioms
\begin{align*}
  & \Kor(s, \varphi, \psi) 
  = \Knot(s, \Kand(s, \Knot(s, \varphi), \Knot(s, \psi)))
  \\
  & \Kimplies(s, \varphi, \psi) 
  = \Kor(s, \Knot(s, \varphi), \psi)
  \\
  & \Kiff(s, \varphi, \psi) 
  = \Kand(s, \Kimplies(s, \varphi, \psi), \Kimplies(s, \psi, \varphi))
  \\
  & \Kforall(s, v, \varphi) 
  = \Knot(s, \Kexists(s, v, \Knot(s, \varphi)))
  \\
  & \Kceil(s_1, s_2, \varphi) =
    \Kapplication(\KSymbolceil(s_1, s_2), \varphi)
  \\
  & \Kfloor(s_1, s_2, \varphi) 
  = \Knot(s_2, \Kceil(s_1, s_2, \Knot(s_1, \varphi)))
  \\
  & \Kequals(s_1, s_2, \varphi, \psi) 
  = \Kfloor(s_1, s_2, \Kiff(s_1, \varphi, \psi))
  \\
  & \Kmembership(s_1, s_2, v, \psi) 
  = \Kceil(s_1, s_2, \Kand(s_1, v, \psi))
  \\
  & \Ktop(s) = \Kexists(s, \Kvariable(x, s), \Kvariable(x, s))
  \\
  & \Kbottom(s) = \Knot(s, \Ktop(s))
\end{align*}

\begin{notation}
	As one may have already noticed, patterns of sort $\KPattern$ get huge rather quickly.
	The following notation conventions are adopted to write $\KPattern$ patterns in a more compact way, by putting a bar upon their normal mixfix forms
	\begin{align*}
	  & \overline{x \cln s} \equiv \Kvariable(x, s) \\
	  & \quad \ \text{or } \KVariableToKPattern(\Kvariable(x, s))
	  \\
	  & \overline{\sigma(\varphi_1, \dots, \varphi_n)} \equiv \Kapplication(\sigma, (\varphi_1, \dots, \varphi_n))
	  \\
	  & \overline{\varphi \wedge_s \psi} \equiv \Kand(s, \varphi, \psi)
	  \\
	  & \overline{\neg_s \varphi} \equiv \Knot(s, \varphi)
	  \\
	  & \overline{\exists_s v . \varphi} \equiv 
	  \Kexists(s, v, \varphi)
	  \\
	  & \overline{\varphi \vee_s \psi} \equiv \Kor(s, \varphi, \psi)
	  \\
	  & \overline{\varphi \to_s \psi} \equiv \Kimplies(s, \varphi, \psi)
	  \\
	  & \overline{\varphi \leftrightarrow_s \psi} \equiv \Kiff(s, \varphi, \psi)
	  \\
	  & \overline{\forall_s v . \varphi} \equiv \Kforall(s, v, \varphi)
      \\
      & \overline{\ceil{\varphi}_{s_1}^{s_2}} \equiv \Kceil(s_1, s_2, \varphi)
      \\
      & \overline{\floor{\varphi}_{s_1}^{s_2}} \equiv \Kfloor(s_1, s_2, \varphi)
      \\
      & \overline{\varphi =_{s_1}^{s_2} \psi} \equiv \Kequals(s_1, s_2, 
      \varphi, \psi)
      \\
      & \overline{v \in_{s_1}^{s_2} \psi} \equiv \Kmembership(s_1, s_2, v, 
      \psi)
      \\
      & \overline{\top_s} \equiv \Ktop(s)
      \\
      & \overline{\bot_s} \equiv \Kbottom(s)
	\end{align*}
	Notice that we overload the notation $\overline{x \cln s}$ for both 
	the $\KVariable$ pattern $\Kvariable(x, s)$ and the $\KPattern$ pattern 
	$\KVariableToKPattern(\Kvariable(x, s))$, so that it can be used in both 
	$\KVariable$ and $\KPattern$ sort contexts, and as a result, it reduces the 
	number of times we explicitly write the injection function 
	$\KVariableToKPattern$.
\end{notation}

Apart from the five constructors and ten derived connectives introduced above, the sort $\KPattern$ also gets some common operators defined as functional symbols.
Those functional symbols are defined and axiomatized in the following 
subsections.

\paragraph{Free Variable Collection.}
The functional symbol 
$$\KgetFvs \colon \KPattern \to \KVariableList$$
traverses the argument pattern and collects all its free variables.
If a variable has multiple occurrences in the pattern, it has the same 
number of occurrences in the result list.
A related functional symbol is 
$$ \KgetFvsFromPatterns \colon \KPatternList \to \KVariableList $$
which takes a list of patterns and applies $\KgetFvs$ on each of them, and returns the concatenation of the results.
\begin{notation}
	As a naming convention, we use $L$ and $R$ for $\KPatternList$ variables. 
\end{notation}
The next seven axioms define $\KgetFvs$ and $\KgetFvsFromPatterns$, with the 
first five of them defining $\KgetFvs$ and the last two defining 
$\KgetFvsFromPatterns$.
Recall that we use $(v)$ to denote the singleton list that consists of only one 
element $v$ (see Notation~\ref{notation:lists}).
\begin{align*}
& \KgetFvs(v) = (v)
\\
& \KgetFvs(\overline{\sigma(L)}) = \KgetFvsFromPatterns(L)
\\
& \KgetFvs(\overline{\varphi \wedge_s \psi}) = \KappendKPatternList(\KgetFvs(\varphi), \KgetFvs(\psi))
\\
& \KgetFvs(\overline{\neg_s \varphi}) = \KgetFvs(\varphi)
\\
& \KgetFvs(\overline{\exists_s v . \varphi}) = \KdeleteKPatternList(v, 
\KgetFvs(\varphi))
\\
& \KgetFvsFromPatterns(\KnilKPatternList) = \KnilKPatternList
\\
& \KgetFvsFromPatterns(\KconsKPatternList(\varphi, L))
\\
& = \KappendKPatternList(\KgetFvs(\varphi), \KgetFvsFromPatterns(L))
\end{align*}

The predicate symbol
$$ \KoccursFree \colon \KVariable \times \KPattern \to \KPred $$
decides whether a variable occurs free in a given pattern
\begin{align*}
  \KoccursFree(v, \varphi) = \KinKPatternList(v, \KgetFvs(\varphi))
\end{align*}

\paragraph{Fresh Variable Name Generation.}
The functional symbol
$$\KfreshName \colon \KPatternList \to \KString$$ 
generates a fresh variable name that does not occur free in the argument list of patterns.
It has the following axiom
\begin{align*}
\neg(\KinKPatternList(\Kvariable(\KfreshName(L), s), \KgetFvsFromPatterns(L)))
\end{align*}

\paragraph{Substitution.}
The functional symbol
$$\Ksubstitute \colon \KPattern \times \KPattern \times \KVariable \to 
\KPattern$$
takes a target pattern $\varphi$, a ``replace''-pattern $\psi$, and a 
``find''-variable $v$, and returns $\varphi[\psi / v]$, the pattern in 
which all free occurrences of variable $v$ are placed with $\psi$
with respect to alpha-renaming.

A related function is 
$$\KsubstitutePatterns \colon \KPatternList \times \KPattern \times \KString \times \KSort \to \KPatternList$$
which takes a list of patterns and applies $\Ksubstitute$ on each of them, and finally returns the list of all the results.

\begin{notation}
	We abbreviate 
	$$\Ksubstitute(\varphi, \psi, v) \equiv \overline{\varphi[\psi / v]}$$
	and 
	$$\KsubstitutePatterns(L, \psi, v) \equiv 
	\overline{L[\psi / v]}$$
	for any $\KPatternList$ pattern $L$.
\end{notation}

The functional symbols $\Ksubstitute$ and $\KsubstitutePatterns$ have the 
following axioms. Recall that we use $v, u$ for $\KVariable$ variables (see 
Notation~\ref{notation:variables-about-KPattern}), and $L$ for $\KPatternList$ 
variable. 
\begin{align*}
  & \overline{u [\psi / v]} 
  = ((u = v) \wedge \psi)
  \vee ((u \neq v) \wedge u)
  \\
  & \overline{\sigma(L [\psi / v])} = 
  \overline{\sigma(L[\psi / v])}
  \\
  & \overline{(\varphi_1 \wedge_{s} \varphi_2) [\psi / v]} = 
  \overline{\varphi_1[\psi / v] \wedge_{s} \varphi_2[\psi / v]}
  \\
  & \overline{(\neg_{s} \varphi)[\psi / v]} = \overline{\neg_{s} \varphi[\psi 
  / v]}
  \\
  & \overline{(\exists_s u . \varphi)[\psi/v]} \\
  & = \exists u' . \left(u' = \Kvariable(\KfreshName(\varphi, \psi, v), 
  \KgetSort(u)) 
  \wedge \overline{\exists_s u' . (\varphi[u' / u][\psi/v])}\right)
  \\
  & \overline{\KnilKPatternList[\psi / v]} = \KnilKPatternList
  \\
  & \overline{\KconsKPatternList(\varphi, L)[\psi / v]} = 
  \KconsKPatternList(\overline{\varphi[\psi / v]}, \overline{L[\psi / v]})
\end{align*}

\paragraph{Alpha-Renaming and Alpha-Equivalence.}
In matching logic, alpha-renaming is always assumed.
This means that the pattern set of a matching logic theory is the one that is generated by the grammar of matching logic patterns in Figure~\ref{ml-grammar}, \emph{modulo alpha-renaming}.
In other words, matching logic patterns are equivalence classes with respect to alpha-equivalence.
This fact is captured in $\Kfinite$ by the next axiom
$$
\KoccursFree(v_1, \varphi) \wedge \KoccursFree(v_2, \varphi) \to 
\overline{\exists_s v_1 .(\varphi[v_1 / u])} = 
\overline{\exists_s v_2 .(\varphi[v_2 / u])}
$$

\subsection{Matching Logic Theories}
\label{sec:ML-theories}


\paragraph{Theory as Predicates.}
A theory declares some sorts, so in $\Kfinite$ there is a predicate symbol
$$ \KsortDeclared \colon \KSort \to \KPred$$
A theory declares some symbols, so in $\Kfinite$ there is a predicate symbol
$$ \KsymbolDeclared \colon \KSymbol \to \KPred$$
with an axiom that says the definedness symbol is always declared
$$ \KsortDeclared(s_1) \wedge \KsortDeclared(s_2) \to 
\KsymbolDeclared(\KSymbolceil(s_1, s_2))$$
A theory declares some patterns as axioms, so in $\Kfinite$ there is a 
predicate symbol
$$ \KaxiomDeclared \colon \KPattern \to \KPred$$

(\textsc{Sort Declaration}).
$\mathit{S}$ is declared as a non-parametric sort with~``S'' being its name.
$$
\KsortDeclared(\Ksort(\text{``S''}))
$$

(\textsc{Symbols Declaration}).
$\mathit{sigma} \colon S_1 \times \dots \times S_n \to S$ is declared as a 
symbol with ``sigma'' being it name.
\begin{equation*}
\KsymbolDeclared(\Ksymbol(\text{``sigma''}, 
(\denote{S_1},\dots,\denote{S_n}), \denote{S}))
\end{equation*}

(\textsc{Axiom Declaration}). 
$\varphi$ is declared to be an axiom.
$$\KaxiomDeclared(\denote{\varphi})$$

\paragraph{Wellformedness.}
The predicate symbol
$$\KwellFormed \colon \KPattern \to \KPred$$ 
decides whether a pattern is \emph{wellformed pattern}.
A related predicate symbol $\KwellFormedPatterns$ checks whether multiple 
patterns are all wellformed
$$ \KwellFormedPatterns \colon \KPatternList \to \KPred$$
with two axioms
\begin{align*}
& \KwellFormedPatterns(\KnilKPatternList) \\
& \KwellFormedPatterns(\varphi, L) = \KwellFormed(\varphi) \wedge 
\KwellFormedPatterns(L)
\end{align*}

The partial function
$$\KgetSort \colon \KPattern \rightharpoonup \KSort$$
returns the sort of a pattern if the pattern is wellformed.
Otherwise, it returns $\bot_\KSort$.
A related partial function is 
$$ \KgetSortsFromPatterns \colon \KPatternList \rightharpoonup \KSortList
$$
which takes a pattern lists and applies $\KgetSort$ on each element, and 
returns 
the list of results.
It has two straightforward axioms
\begin{align*}
  & \KgetSortsFromPatterns(\KnilKPatternList) = \KnilKSortList
  \\
  & \KgetSortsFromPatterns(\varphi, L) = \KgetSort(\varphi), 
  \KgetSortsFromPatterns(L)
\end{align*}

The partial functions $\KwellFormed$ and $\KgetSort$ are defined by the following axioms
\begin{align*}
  &\KwellFormed(\overline{x \cln s}) = \KsortDeclared(s)
  \\
  & \KwellFormed(\overline{\sigma(L)}) 
  = \KsymbolDeclared(\sigma) 
  \wedge \KwellFormedPatterns(L)
  \\
  & \quad \wedge (\KgetSortsFromPatterns(L) = \KgetArgumentSorts(\sigma))
  \\
  & \KwellFormed(\overline{\varphi \wedge_s \psi}) 
  = \KwellFormed(\varphi) \wedge \KwellFormed(\psi)
  \\
  & \quad \wedge (\KgetSort(\varphi) = s) \wedge (\KgetSort(\psi) = s)
  \\
  & \KwellFormed(\overline{\neg_s \varphi}) = \KwellFormed(\varphi)
    \wedge (\KgetSort(\varphi) = s)
  \\
  & \KwellFormed(\overline{\exists_s v . \varphi}) =
  \KwellFormed(v) \wedge \KwellFormed(\varphi) \wedge (\KgetSort(\varphi) = s)
  \\
  & \KgetSort(\overline{x \cln s}) = \KwellFormed(\overline{x \cln s}) \wedge s
  \\
  & \KgetSort(\overline{\sigma(L)}) = \KwellFormed(\overline{\sigma(L)}) \wedge 
  \KgetReturnSort(\sigma)
  \\
  & \KgetSort(\overline{\varphi \wedge_s \psi}) = 
  \KwellFormed(\overline{\varphi \wedge_s \psi}) \wedge s
  \\
  & \KgetSort(\overline{\neg_s \varphi}) = \KwellFormed(\overline{\neg_s 
  \varphi}) \wedge s
  \\
  & \KgetSort(\overline{\exists_s v . \varphi}) = 
  \KwellFormed(\overline{\exists_s v . \varphi}) \wedge s
\end{align*}

\subsection{Matching Logic Proof System}
\label{sec:ML-proof-system}

The Hilbert-style proof system of matching logic in~\cite{rosu-2017-lmcs} 
defines the \emph{derivability} of a pattern in an inductive manner.
It defines a recursive set of patterns as \emph{logic axioms} (in terms of 
logic 
schemas) and 
says 
all logic axioms are derivable.
It also consists of four inference rules schemas---\textsc{(Modus Ponens)}, 
\textsc{(Universal Generalization)}, \textsc{(Membership Introduction)}, 
\textsc{(Membership Elimination)}---that if some patterns (called the premises) 
are derivable, then a pattern (called the conclusion) is also derivable.
The set of all derivable patterns according to the proof system is the smallest 
set of patterns that contains all logic axioms and are closed under the four 
inference rules schemas.

For the purpose of a unified perspective, we regard logic axiom schemas as 
inference 
rule schemas with zero premise.

Such inductiveness of derivability is naturally captured by 
introducing a predicate symbol
$$
\Kdeduce \colon \KPattern \to \KPred
$$
which has axioms in correspondent to every inference rules:
$$\Kderivable(\denote{\varphi_1}) \wedge \dots \wedge 
\Kderivable(\denote{\varphi_n}) \to \Kderivable(\denote{\psi})$$
is an axiom in the meta-theory if and only if 
$$
	\prftree
	{ \varphi_1 \dots  \varphi_n}
	{ \psi }
$$
is an inference rule of matching logic, in which $\denote{\varphi_1}, \dots, 
\denote{\varphi_n}, \denote{\psi}$ are representations of $\varphi_1, \dots, 
\varphi_n, \psi$ in the meta-theory.

In the following, we list all the inference rules of the matching logic proof 
system and the correspondent axioms of $\Kdeduce$. We recall the readers our 
conventions of choosing variable names. 
We use 
$x$ and $y$ for $\KString$ variables,
$s$ for $\KSort$ variables,
$\varphi$ and $\psi$ for $\KPattern$ variables,
$L$, $R$ for $\KPatternList$ variables~(in \textbf{Rule~(M5)}).

(\textsc{Axiom}).\quad
$A \vdash \varphi$ if $\varphi \in A$.
\begin{equation*}
\KaxiomDeclared(\varphi) \to \Kdeduce(\varphi)
\end{equation*}

\paragraph{Propositional Logic Inference Rules.}\quad
\\

(\textsc{Propositional$_1$}).\quad
$\vdash \varphi \to (\psi \to \varphi)$.
\begin{equation*}
\forall \varphi \forall \psi \forall s \left(
\KwellFormed(\overline{\varphi \to_s (\psi \to_s  \varphi)}) \to
\Kdeduce(\overline{\varphi \to_s (\psi \to_s  \varphi)})\right)
\end{equation*}

Just for simplicity, from now on we omit writing the wellformedness premises, 
though it does not mean they are unimportant.
They are crucial in proving the faithfulness of the meta-theory.
We also omit explicitly quantifying free variables.
\\

(\textsc{Propositional$_2$}).\quad
$\vdash (\varphi_1 \to (\varphi_2 \to \varphi_3)) \to ((\varphi_1 \to \varphi_2) \to (\varphi_1 \to \varphi_3))$.
\begin{equation*}
\Kdeduce(
\overline{(\varphi_1 \to_s (\varphi_2 \to_s \varphi_3)) \to_s ((\varphi_1 \to_s 
\varphi_2) \to_s (\varphi_1 \to_s \varphi_3))}).
\end{equation*}

(\textsc{Propositional$_3$}).\quad
$\vdash (\neg \psi \to \neg \varphi) \to (\varphi \to \psi)$.
\begin{equation*}
\Kdeduce(\overline{(\neg_s \psi \to_s \neg_s \varphi) 
\to_s (\varphi 
\to_s \psi)}).
\end{equation*}

(\textsc{Modus Ponens}).\quad
If $\vdash \varphi$ and $\vdash \varphi \to \psi$, then $\vdash \psi$.
\begin{equation*}
\Kdeduce(\varphi) \wedge \Kdeduce(\overline{\varphi \to_s \psi}) 
\to 
\Kdeduce(\psi).
\end{equation*}

\paragraph{First-Order Logic With Equality Inference Rules.} \quad
\\

(\textsc{$\forall$}).\quad
$\vdash \forall v . (\varphi \to \psi) \to (\varphi \to \forall v . \psi)$ if 
$v$ does not occur free in $\varphi$. 
\begin{equation*}
\neg\KoccursFree(v, \varphi)
\to \Kdeduce(\overline{\forall_s v . (\varphi \to_s	\psi) \to_s (\varphi \to_s 
\forall_s v . \psi)}).
\end{equation*}

(\textsc{Universal Generalization}).\quad
If $\vdash \varphi$, then $\vdash \forall v . \varphi$.
\begin{equation*}
\Kdeduce(\varphi) \to \Kdeduce(\overline{\forall_s v . \varphi}).
\end{equation*}

(\textsc{Functional Substitution}).\quad
$\vdash \exists u . u = \psi \wedge \forall v . \varphi \to \varphi[\psi/v]$ if 
$u$ does not occur free in $\psi$.
\begin{equation*}
\KoccursFree(u, \psi) \to
\Kdeduce(\overline{\exists_{s_2} u . u =_{s_1}^{s_2} \psi \wedge_{s_2} 
\forall_{s_2} v . \varphi \to_{s_2} \varphi[\psi/v]}).
\end{equation*}

(\textsc{Functional Variable}). \quad
$\vdash \exists u . u =v $
$$
\Kdeduce(\overline{\exists_{s_2} u . u =_{s_1}^{s_2} v})
$$

(\textsc{Equality Introduction}).\quad
$\vdash \varphi = \varphi$
$$\Kdeduce(\overline{\varphi =_{s_1}^{s_2} \varphi})$$

(\textsc{Equality Elimination}).\quad
$\vdash (\varphi_1 = \varphi_2) \to (\psi[\varphi_1/v] \to \psi[\varphi_2/v])$.
\begin{equation*}
\Kdeduce(\overline{(\varphi_1 =_{s_1}^{s_2} \varphi_2) \to_{s_2} 
(\psi[\varphi_1/v] \to_{s_2} \psi[\varphi_2/v])}).
\end{equation*}

\paragraph{Definedness Axioms.}\quad
\\

(\textsc{Defined Variable}).
$\vdash \ceil{x \cln s}$.
\begin{equation*}
\Kdeduce(\Kceil(s, s', \overline{x \cln s})).
\end{equation*}

\paragraph{Membership Rules.}\quad
\\


(\textsc{Membership Introduction}).
If $\vdash \varphi$, and $v$ does not occur free in $\varphi$, then $\vdash v 
\in \varphi$.
\begin{equation*}
\Kdeduce(\varphi) \wedge \neg \KoccursFree(v, \varphi) \to \Kdeduce(\overline{v 
\in_{s_1}^{s_2} \varphi}).
\end{equation*}

(\textsc{Membership Introduction}).
If $\vdash v \in \varphi$ and $v$ does not occur free in $\varphi$, then 
$\vdash \varphi$.
\begin{equation*}
\Kdeduce(\overline{v \in_{s_1}^{s_2} \varphi}) \wedge \neg 
\KoccursFree(v, \varphi) \to \Kdeduce(\varphi).
\end{equation*}

(\textsc{Membership Variable}).
$\vdash (v \in u) = (v = u)$.
\begin{equation*}
\Kdeduce(\overline{(v \in_{s_1}^{s_2} u) =_{s_2}^{s_3} (v =_{s_1}^{s_2} u)}).
\end{equation*}

(\textsc{Membership $\wedge$}).
$\vdash v \in (\varphi \wedge \psi) = (v \in \varphi) \wedge (v \in \psi).$
\begin{equation*}
\Kdeduce(\overline{v \in_{s_1}^{s_2} (\varphi \wedge_{s_1} \psi) =_{s_2}^{s_3} 
(v \in_{s_1}^{s_2} \varphi) \wedge_{s_2} (v \in_{s_1}^{s_2} \psi)}).
\end{equation*}

(\textsc{Membership $\neg$}).
$\vdash v \in \neg \varphi = \neg (v \in \varphi)$.
\begin{equation*}
\Kdeduce(\overline{v \in_{s_1}^{s_2} \neg_{s_1} \varphi =_{s_2}^{s_3} 
\neg_{s_2} (v \in_{s_1}^{s_2} \varphi)}).
\end{equation*}

(\textsc{Membership $\forall$}).
$\vdash v \in \forall u . \varphi = \forall u . v \in \varphi$ if $v$ is 
distinct from $u$.
\begin{equation*}
(v \neq u)  \to \Kdeduce(\overline{(v \in_{s_1}^{s_2} \forall_{s_1} u . 
\varphi) =_{s_2}^{s_3} 
(\forall_{s_2} u . (v \in_{s_1}^{s_2} \varphi))}).
\end{equation*}

(\textsc{Membership Symbol}).
$\vdash v \in \sigma(\dots \varphi_i \dots) = \exists u . u \in \varphi_i 
\wedge v \in \sigma(\dots u \dots)$ where $u$ is distinct from $v$ and it does 
not occur free in $\sigma(\dots \varphi_i \dots)$.
\begin{align*}
& (u \neq v) 
  \wedge \neg \KoccursFree(u, \overline{\sigma(L, \varphi_i, R)})
\\
\to & \Kdeduce(\overline{v \in_{s_1}^{s_2} \sigma(L, \varphi_i, R) 
=_{s_2}^{s_3} \exists_{s_2} u . (u \in_{s_4}^{s_2} \varphi_i \wedge_{s_2} v 
\in_{s_1}^{s_2} \sigma(L, u, R))}),
\end{align*}
where $L$ and $R$ are $\KPatternList$ variables, and we write $(L, \varphi, R)$ as a shorthand of
$$(L, \varphi, R) \equiv \KappendKPatternList(L, \KconsKPatternList(\varphi, 
R)).$$

\subsection{A Summary of the Meta-Theory}
\label{sec:K-summary}


\section{Reflect Theories in the Meta-Theory}
\label{sec:reflect}
We have shown the readers the big picture of the meta-theory $K$ and its usage in Section~\cref{sec:meta-theory}.
In this section, we will show in detail how to \emph{lift} any r.e. matching logic theory $T$ to its meta-representation $\denote{T}$, and present the faithfulness theorem of $K$.

\subsection{Naming Functions}
A naming function associates any object to a string, called its \emph{name}.
For example, $\Bool$ is a non-parametric sort in Boolean algebra, and the string ``Bool'' is its name.
$\List$ is a parametric sort, and the string ``List'' is its name.
A naming function is a prerequisite for anything to be represented in the meta-theory $K$ (see Section~\cref{sec:chars-string}), and in Kore we assume the names of anything is itself wrapped with quotation marks.

\begin{center}
	\begin{tabular}{l|r}
		\textbf{Objects} & \textbf{Names}
		\\\hline
		Non-parametric sort $\Nat$ & ``Nat''
		\\\hline
		Parametric sort $\List$ & ``List''
		\\\hline
		Non-parametric symbol $\zero$ & ``zero''
		\\\hline
		Parametric symbol $\nil$ & ``nil''
		\\\hline
		Parametric symbol $\cons$ & ``cons''
		\\\hline
		Parametric symbol $\append$ & ``append''
	\end{tabular}
	\captionof{table}{Naming Function Example}
\end{center}

In the following subsections, we fix a matching logic theory $T = (S, \Sigma, A)$ and a naming function $\name$, and show how to get $\denote{T}$.

\subsection{Reflect Sorts}
The \emph{sort lifting operation} is a mapping
$$ \denote{\_} \colon S \to \PATTERNS_\KSort $$
inductively defined as
\begin{align*}
&\denote{s} = \Ksort(\name(s), \KnilKSortList) & \text{if $s \in S$ is a basic sort} \\
&\denote{\parametric{S}{s_1,\dots,s_n}} = \Ksort(\name(S), \denote{s_1,\dots,s_n}) & \text{if $S\{s_1,\dots,s_n\} \in S$ is a sort schema instance}
\end{align*}
where $\denote{s_1,\dots,s_n}$ is the pointwise extension of sort lifting operation on a sequence of sorts:
$$\denote{\_} \colon S^* \to \PATTERNS_\KSortList$$
inductively defined as
\begin{align*}
&\denote{\epsilon} = \KnilKSortList \\
&\denote{s} = \KconsKSortList(\denote{s}, \KnilKSortList) \\
&\denote{s_1,\dots,s_n} = \KconsKSortList(\denote{s_1}, \denote{s_2,\dots,s_n}) \quad \text{if $n \ge 2$}
\end{align*}

If $T$ has a basic sort $s \in S$, we add the following axiom to $\denote{T}$
$$ \KsortDeclared(\denote{s}) $$
If $T$ has a sort schema 
\begin{center}
$\parametric{S}{s_1,\dots,s_n} \in S$ \quad for any $s_1,\dots,s_n \in S$
\end{center}
we add the following axiom to $\denote{T}$
$$ \KsortDeclared(s_1) \wedge \dots \wedge \KsortDeclared(s_n) \to \KsortDeclared(\denote{\parametric{S}{s_1,\dots,s_n}}) $$

\subsection{Reflect Symbols}
The \emph{symbol lifting operation} is a mapping
$$ \denote{\_} \colon \Sigma \to \PATTERNS_\KSymbol $$
For any basic symbol $\sigma \colon s_1 \times \dots \times s_n \to s$, define
$$\denote{\sigma} = \Ksymbol(\name(\sigma), \KnilKSortList, \denote{s_1,\dots,s_n}, \denote{s})$$
and any symbol schema instance $\parametric{\sigma}{s_1',\dots,s_m'} \colon s_1 \times \dots \times s_n \to s$, define
$$\denote{\parametric{\sigma}{s_1',\dots,s_m'}} = \Ksymbol(\name(\sigma), \denote{s_1',\dots,s_m'}, \denote{s_1,\dots,s_n}, \denote{s})$$

For $T$ has a basic symbol $\sigma$, add the following axiom to $\denote{T}$
$$ \KsymbolDeclared(\denote{\sigma})$$

If $T$ has symbol a symbol schema
\begin{center}
	$\parametric{\sigma}{s_1,\dots,s_n} \in S$ \quad for any $s_1,\dots,s_n \in S$
\end{center}
then add the following axiom to $\denote{T}$
$$ \KsortDeclared(s_1) \wedge \dots \wedge \KsortDeclared(s_n) \to
   \KsymbolDeclared(\denote{\parametric{\sigma}{s_1,\dots,s_n}})
$$

\subsection{Reflect Variables}
Define the set of variables in $T$
$$\VARIABLES_T = \bigcup_{\text{$x \in N$ is a variable name and $s\in S$ is a sort in $T$}} x \cln s$$
The \emph{variable lifting operation}
$$\denote{\_}_0 \colon \VARIABLES_T \to \PATTERNS_\KVariable$$
is defined as
$$\denote{x \cln s}_0 = \Kvariable(\name(x), \denote{s})$$

\subsection{Reflect Patterns and Axioms}
Just like how we reflect sorts and symbols, patterns are reflected by lifting to their corresponding abstract syntax trees, too.
Let us define the set of all patterns in $T$
$$\PATTERNS_T = \bigcup_{\text{$s\in S$ is a sort in $T$}} \PATTERNS_s$$
The \emph{pattern lifting operation}
$$\denote{\_} \colon \PATTERNS_T \to \PATTERNS_\KPattern$$
and its pointwise extension on pattern lists 
$$\denote{\_} \colon \PATTERNS_T^* \to \PATTERNS_\KPatternList$$
are inductively defined as the follows.
\begin{align*}
&\denote{x \cln s} = \KVariableToKPattern(\denote{x \cln s}_0) \\
&\denote{\sigma(\varphi_1,\dots,\varphi_n)} = \Kapplication(\denote{\sigma}, \denote{\varphi_1,\dots,\varphi_n}) \\
&\denote{\varphi \wedge_s \psi} = \Kand(\denote{s}, \denote{\varphi}, \denote{\psi}) \\
&\denote{\neg_s \varphi} = \Knot(\denote{s}, \denote{\varphi}) \\
&\denote{\exists_s^{s'} x \cln s . \varphi} = \Kexists(\denote{s}, \denote{{s'}}, \denote{x \cln s}_0, \denote{\varphi}) \\
&\denote{\varphi \vee_s \psi} = \Kor(\denote{s}, \denote{\varphi}, \denote{\psi}) \\
&\denote{\varphi \to_s \psi} = \Kimplies(\denote{s}, \denote{\varphi}, \denote{\psi}) \\
&\denote{\varphi \leftrightarrow_s \psi} = \Kiff(\denote{s}, \denote{\varphi}, \denote{\psi}) \\
&\denote{\forall_s^{s'} x \cln s . \varphi} = \Kforall(\denote{s}, \denote{{s'}}, \denote{x \cln s}_0, \denote{\varphi}) \\
&\denote{\ceil{\varphi}_s^{s'}} = \Kceil(\denote{s}, \denote{{s'}}, \denote{\varphi})\\
&\denote{\floor{\varphi}_s^{s'}} = \Kfloor(\denote{s}, \denote{{s'}}, \denote{\varphi})\\
&\denote{\varphi =_s^{s'} \psi} = \Kequals(\denote{s}, \denote{s'}, \denote{\varphi}, \denote{\psi})\\
&\denote{x \cln s \in_s^{s'} \varphi} = \Kmembership(\denote{s}, \denote{s'}, \denote{x \cln s}_0, \denote{\varphi})\\
&\denote{\top_s} = \Ktop(\denote{s})\\
&\denote{\bot_s} = \Kbottom(\denote{s})
\end{align*}
Notice that we do not desugar derivative connectives such as disjunction or universal quantification.
Instead, we keep them as it is when lifting them to the meta-theory.
Also notice how the injection wrapper $\KVariableToKPattern$ is used.

If $\varphi$ is an axiom in $T$, add the following axiom to $\denote{T}$
$$ \KaxiomDeclared(\denote{\varphi})$$
If $\varphi$ is an axiom schema with $s_1,\dots,s_n$ are sort parameters, add the following axiom to $\denote{T}$
$$ \KsortDeclared(s_1) \wedge \dots \wedge  \KsortDeclared(s_n) \to \KaxiomDeclared(\denote{\varphi}) $$



%\subsection{Example A: Arithmetic \& Parametric Lists}
%
%\begin{lstlisting}[language=kore]
%/*** natlist.kore ***/
%sort Nat
%sort List{S}
%symbol zero() : Nat
%symbol succ(Nat) : Nat
%symbol nil{S}() : List{S}
%symbol cons{S}(S, List{S}) : List{S}
%symbol append{S}(List{S}, List{S}) : List{S}
%axiom{S,S'} equals{List{S}, S'}(
%append{S}(nil{S}(), L:List{S}),
%L:List{S})
%\end{lstlisting}
%
%
%\paragraph{Abstract Syntax Trees.}
%As soon as we have a naming function, we can encode sorts, symbols, and 
%patterns by their abstract syntax trees in the meta-theory $K$.
%A majority portion of the meta-theory $K$ is about the construction of abstract 
%syntax trees of sorts, symbols, and patterns, and common operations on those 
%abstract syntax trees (for more details, please refer to Sections~\cref{sec:ML-sorts-symbols,sec:ML-patterns,sec:meta-theory-sort-parameters}).
%
%\begin{center}
%	\begin{tabular}{l|r}
%		\textbf{Objects} & \textbf{Abstract Syntax Trees as Patterns in $K$}
%		\\\hline
%		Non-parametric sort $\Nat$ & $\Ksort(\text{``Nat''}, \KnilKSortList)$
%		\\\hline
%		Parametric sort $\parametric{\List}{\Nat}$ & $\Ksort(\text{``List''}, \KconsKSortList(\Ksort(\text{``Nat''}, \KnilKSortList),$ \\ & $\KnilKSortList))$
%		\\\hline
%		Non-parametric constant symbol $\zero$ & $\Ksymbol(\text{``zero''}, \KnilKSortList, \KnilKSortList,$ \\ &
%		$\Ksort(\text{``Nat''}, \KnilKSortList))$
%		\\\hline
%		Parametric symbol $\parametric{nil}{\Nat}$ & See equation~\eqref{nil-Nat}
%		\\\hline
%		Parametric symbol $\parametric{\cons}{\Nat}$ & See equation~\eqref{cons-Nat}
%	\end{tabular}
%	\captionof{table}{Objects and Their Abstract Syntax Trees (Without Notation Sugar)}
%\end{center}
%
%\paragraph{Abstract Syntax Trees With Sugar.}
%As we have seen, abstract syntax trees are huge even for the simplest object.
%To simplify our notation with abstract syntax trees, we introduce intermediate symbols (notation sugar) to allow us write more compact patterns in $K$.
%For example, instead of writing
%$$\Ksort(\text{``Nat''}, \KnilKSortList)$$
%over and over again, we introduce a new constant symbol $\KNat$ to the meta-theory with the axiom
%$$ \KNat = \Ksort(\text{``Nat''}, \KnilKSortList) $$
%For parametric sort $\List$, we introduce a unary symbol $\KList$ which takes a sort as parameter, with axiom
%$$ \KList(s) = \Ksort(\text{``List''}, \KconsKSortList(s, \KnilKSortList)) $$
%Basically, we could introduce as much notation sugar as we want to the meta-theory in order to make writing abstract syntax trees less painful.
%
%\begin{center}
%	\begin{tabular}{l|r}
%		\textbf{Objects} & \textbf{Abstract Syntax Trees as Patterns in $K$}
%		\\\hline
%		Non-parametric sort $\Nat$ & $\KNat$
%		\\\hline
%		Parametric sort $\parametric{\List}{\Nat}$ & $\KList(\KNat)$
%		\\\hline
%		Non-parametric constant symbol $\zero$ & $\KSymbolzero$
%		\\\hline
%		Parametric symbol $\parametric{nil}{\Nat}$ & $\KSymbolnil(\KNat)$
%		\\\hline
%		Parametric symbol $\parametric{\cons}{\Nat}$ & $\KSymbolcons(\KNat)$
%		\\\hline
%		Pattern $zero$ & $\Kzero$
%		\\\hline
%		Pattern $\parametric{\cons}{\Nat}(\zero, \parametric{\nil}{\Nat})$
%		& $\Kcons(\KNat, \Kzero, \Knil(\KNat))$
%	\end{tabular}
%	\captionof{table}{Objects and Their Abstract Syntax Trees (With Notation Sugar)}
%	\label{tab:ast-with-sugar}
%\end{center}
%
%Such transformation from objects to their abstract syntax trees with notation sugar as shown in Table~\ref{tab:ast-with-sugar} is the \emph{lifting} operation ``$\denote{\ \ \ }$''.
%
%Adding sugar for abstract syntax trees means we add some new symbols (such as $\KNat$) and new axioms to the meta-theory $K$.
%
%
%\paragraph{Declarations as Assertions.}
%
%A Kore definition contains some sort, symbol, and axiom declarations, whose formal semantics are given in the meta-theory with three predicate symbols: $\KsortDeclared$, $\KsymbolDeclared$, and $\KaxiomDeclared$ (See Section~\cref{sec:ML-theories}).
%
%\begin{center}
%	\begin{tabular}{l|r}
%		\textbf{Declarations} & \textbf{Assertions Added to the Meta-Theory $K$}
%		\\\hline
%		\texttt{sort Nat} & $\KsortDeclared(\KNat)$
%		\\\hline
%		\texttt{sort List\{S\}} & $\KsortDeclared(s) \to \KsortDeclared(\KList(s))$
%		\\\hline
%		\texttt{symbol zero():Nat} & $\KsymbolDeclared(\KSymbolzero)$
%		\\\hline
%		\texttt{symbol succ(Nat):Nat} & $\KsymbolDeclared(\KSymbolsucc)$
%		\\\hline
%		\texttt{symbol nil\{S\}():List\{S\}} & $\KsortDeclared(s)\to\KsymbolDeclared(\KSymbolnil(s))$
%		\\\hline
%		\texttt{symbol cons\{S\}(S,List\{S\}):List\{S\}} & $\KsortDeclared(s)\to\KsymbolDeclared(\KSymbolcons(s))$
%		\\\hline
%		\texttt{axiom $\varphi$} & $\Kdeduce(\denote{\varphi})$
%		\\\hline
%		\texttt{axiom\{S\} $\varphi$} & $\KsortDeclared(s) \to \Kdeduce(\denote{\varphi})$
%		\\\hline
%		\texttt{axiom\{S1,..,Sn\} $\varphi$} & $\KsortDeclared(s_1) \wedge \dots \wedge \KsortDeclared(s_n) \to \Kdeduce(\denote{\varphi})$
%	\end{tabular}
%	\captionof{table}{Lift Declarations to Assertions}
%	\label{tab:declarations-as-assertions}
%\end{center}
%
%\paragraph{Lifting Kore Definitions.} Given kore definition ``\texttt{natlist.kore}'', its lifting is a kore definition with notation sugar defined as symbols and declarations defined as axioms:

%\subsection{Example B: Rewriting with Contexts}
%\begin{lstlisting}[language=kore]
%/*** ctxt.kore ***/
%sort Ctxt{S1,S2}
%symbol gamma0{S1,S2}(S1,S2):Ctxt{S1,S2}
%symbol ctxtapp{S1,S2}(Ctxt{S1,S2},S1):S2
%alias{S1,S2} gamma{S1,S2}(H:KVariable, P:KPattern) 
%:= exists{S1,S2}(H:KVariable, gamma0(H:KVariable, P:KPattern))
%alias{S} idctxt{S}() := gamma{S,S}(H:S,H:S)
%axiom{S,R} equals{S,R}(ctxtapp(idctxt{S}(), P:KPattern), P:KPattern)
%/*** if-then-else is strict on the 1st argument ***/
%sort BExp
%sort Stmt
%symbol ite(BExp,Stmt,Stmt):Stmt
%axiom{S,R} 
%implies{R}(
%choice{KSort,KPattern}(
%equals{KSort,KSort}(KgetSort(C:KPattern), KCtxt(S:KSort,KAExp())),
%top{KPattern}(), 
%bottom{KPattern}()),
%equals{Stmt, R}(
%ite(ctxtapp{S,BExp}(C:KPattern, X:S), S1:Stmt, S2:Stmt),
%ctxtapp{S,BExp}(
%gamma{S,BExp}(
%H:S,
%ite(ctxtapp{S,BExp}(C:KPattern, H:S), S1:Stmt, S2:Stmt)),
%X:S)))
%/*** C[ite(tt,S1,S2)] => C[S1] ***/
%axiom{R}
%rewrites{R}(
%ctxtapp{Stmt,R}(C:KPattern, ite(tt(), S1:Stmt, S2:Stmt)),
%ctxtapp{Stmt,R}(C:KPattern, S1:Stmt))
%/*** C[ite(ff,S1,S2)] => C[S2] ***/
%axiom{R}
%rewrites{R}(
%ctxtapp{Stmt,R}(C:KPattern, ite(ff(), S1:Stmt, S2:Stmt)),
%ctxtapp{Stmt,R}(C:KPattern, S2:Stmt))
%\end{lstlisting}

%
%The theory of lambda calculus, denoted as $L$, has 
%only one sort which we denote as $\Exp$
%\begin{center}
%	(\textsc{Exp}) \quad $\Exp$ is a sort in theory $L$.
%\end{center} It has two binary symbols which we 
%denote as $\lambda_0$ and $\app$, respectively
%\begin{center}
%	(\textsc{Abstraction}) \quad $\lambda_0(\Exp, \Exp) \colon \Exp$ 
%	\\
%	(\textsc{Application}) \quad $\app(\Exp, \Exp) \colon \Exp$ 
%\end{center}
%We introduce the symbol $\lambda$ as an alias defined as
%\begin{center}
%	(\textsc{Binder})\quad $ \lambda(x, e) \coloneqq \exists x . \lambda_0(x, 
%	e)$ \quad for any variable $x$ and $\Exp$ pattern $e$
%\end{center}
%and define a syntactic class called $\lambda$-terms
%\begin{center}
%	(\textsc{$\lambda$-Term}) \quad $\Lambda$-terms is the smallest set 
%	satisfying the following three conditions
%	\begin{itemize}[leftmargin=11em,nosep]
%		\item $x \in \text{$\lambda$-Term}$ for any variable $x$
%		\item $\lambda(x, e) \in \text{$\lambda$-Term}$ for any variable $x$ 
%		and $e \in \text{$\lambda$-Term}$
%		\item $\app(e, e') \in \text{$\lambda$-Term}$ for any $e, e' \in 
%		\text{$\lambda$-Term}$
%	\end{itemize}
%\end{center}
%The theory $\Lambda$ has an axiom schema
%\begin{center}
%	(\textsc{Beta}) \quad $\app(\lambda(x, e), e') = e'[e/x]$ 
%	\quad if $e$ and $e'$ are $\lambda$-terms
%\end{center}
%
%\paragraph{Naming Function.}
%A naming function is needed to encode lambda expressions as abstract syntax 
%trees.
%We use the next naming function
%
%
%
%
%\paragraph{Declarations in $L$ as Assertions in $K$.} \quad
%We list all declarations in $L$ and their corresponding assertions in $K$, 
%without explaining them.
%We will formally define the process in Section~\cref{?}, but for now we only 
%provide a taste of flavor of the meta-theory $K$.
%
%In $L$,
%\begin{center}
%	$\Exp$ is a sort
%\end{center}
%
%In $K$,
%\begin{center}
%	\begin{tabular}{l}
%		$\KExp$ is a constant symbol of sort $\KSort$ \\
%		$\KExp = \Ksort(\text{``Exp''})$ \\
%		$\KsortDeclared(\KExp)$
%	\end{tabular}
%\end{center}
%
%In $L$,
%\begin{center}
%	$\lambda_0$ is a binary symbol
%\end{center}
%
%In $K$,
%\begin{center}
%	\begin{tabular}{l}
%		$\mathit{KSymbollambda0}$ is a constant symbol of sort $\KSymbol$ \\
%		$\mathit{KSymbollambda0} = \Ksymbol(\text{``Exp''}, (\KExp, \KExp), 
%		\KExp)$ \\
%		$\KsymbolDeclared(\mathit{KSymbollambda0})$ \\
%		$\Klambdazero \colon \KPattern \times \KPattern \to \KPattern$ is a 
%		symbol\\
%		$\Klambdazero(\varphi, \psi) = \Kapplication(\mathit{KSymbollambda0}, 
%		(\varphi, \psi))$\\
%	\end{tabular}
%\end{center}
%
%In $L$
%\begin{center}
%	$\lambda$ is an alias defined as $\lambda(x, e) = \exists x . \lambda_0(x, 
%	e)$
%\end{center}
%
%In $K$
%\begin{center}
%	\begin{tabular}{l}
%		$\Klambda \colon \KVariable \times \KPattern \to \KPattern$ is a symbol 
%		\\
%		$\Klambda(v, \varphi) = \Kexists(\KExp, \KExp, v, \Klambdazero(v, 
%		\varphi))$
%	\end{tabular}
%\end{center} 

%\paragraph{Strings.}
%We refer to things in various way.
%For example, we use $\Bool$ to denote the only sort in the theory of Boolean 
%algebra, and $\mathit{zero}$ to denote the constant functional 
%symbol in Peano arithmetic that stands for the natural number zero.
%In philosophy and logic, there is a well-known distinction called the 
%use-mention distinction that distinguishes \emph{using} a word or phrase versus 
%\emph{mentioning} it.
%In the previous sentence, we were \emph{using} but not \emph{mentioning} the 
%sort $\Bool$ and the symbol $\mathit{zero}$.
%A clear evidence of mentioning something is that the thing being mentioned is 
%wrapped with quotation marks.
%For $K$ to be the reflective logic of matching logic, it should be able to 
%contain \emph{every} sorts and symbols that appear in \emph{every} theories, 
%which is simply impossible because there is not such a set as \emph{the set of 
%all matching logic sorts}.
%Instead, we let $K$ contain \emph{all possible mentions} of a matching logic 
%sort or symbol.
%Therefore, instead of having the sort $\Bool$ as part of it, $K$ has \emph{a 
%mention for it}, denoted as the string ``Bool''.
%
%The sort in $K$ for strings is $\KString$, which are defined in 
%Section~\cref{?}.




%
%\subsection{Representing Theories as Assertions on Some Predicates}
%We define matching logic theories and the proof system of matching logic as 
%\emph{sets of predicates over the universe of abstract syntax trees of sorts, 
%symbols, and patterns}.
%This approach is a standard approach in the studies of reflective logics. 
%For example in~\cite{?}, a unary predicate symbol $T$ called the \emph{truth 
%predicate} is used in a reflective logic of propositional logic that satisfies 
%the faithfulness conditions
%\begin{center}
%	\begin{tabular}{ccc}
%		$
%		\prftree[r]{\footnotesize (Upward Reflection)}
%		{\vdash \varphi}
%		{\vdash T(\denote{\varphi})}
%		$
%		&&
%		$
%		\prftree[r]{\footnotesize (Downward Reflection)}
%		{\vdash T(\denote{\varphi})}
%		{\vdash \varphi}
%		$
%	\end{tabular}
%\end{center}
%where $\denote{\varphi}$ is the abstract syntax tree that represents the 
%formula $\varphi$ in the reflective logic.
%Intuitively, the truth predicate $T$ captures the semantics of a formula being 
%true.
%
%We adopt the same approach in this proposal.
%We introduce and axiomatize a finite number of
%predicate symbols in the meta-theory $K$ that capture the semantics of the 
%matching logic proof system, or more specifically, the semantics of
%\begin{itemize}\itemsep0em
%	\item A sort being declared in a theory ($\KsortDeclared$)
%	\item A symbol being decalred in a theory ($\KsymbolDeclared$)
%	\item A pattern being an axiom in a theory ($\KaxiomDeclared$)
%	\item A pattern being wellformed in a theory ($\KwellFormed$)
%	\item A pattern being derivable in a theory ($\Kderivable$)
%\end{itemize}
%
%Each of them has to satisfy the corresponding faithfulness theorem.
%In particular, the faithfulness for the derivability means
%\begin{center}
%	\begin{tabular}{cc}
%		$
%		\prftree[r]{\footnotesize (Upward Reflection)}
%		{T \vdash \varphi}
%		{K \cup \denote{T} \vdash \Kdeduce(\denote{\varphi})}
%		$
%		&
%		$
%		\prftree[r]{\footnotesize (Downward Reflection)}
%		{K \cup \denote{T} \vdash \Kdeduce(\denote{\varphi})}
%		{T \vdash \varphi}
%		$
%	\end{tabular}
%\end{center}
%where $\denote{\varphi}$ is the representation of $\varphi$ in the 
%meta-theory, and $\denote{T}$ is the set of assertions of predicates that 
%defines the theory $T$ in the meta-theory.
%
%
%
%\paragraph{Shallow Embedding and Deep Embedding.}
%There are multiple ways to design a reflective logic.
%For example, we could define the meta-theory $K$ in a way that not only sorts, 
%symbols, and patterns have their abstract syntax trees as terms in the 
%meta-theory, but also signatures and theories.
%We just showed how to define in the meta-theory $K$ a universe of abstract 
%syntax trees of matching logic sorts, symbols, and patterns so that every sort 
%or symbol or pattern gets its (unique) meta-representation in the meta-theory 
%as a term of sort $\KSort$ or $\KSymbol$ or $\KPattern$.
%We could do the same thing for theories, that is, we develop a universe of 
%abstract syntax tree of matching logic theories and go from that.
%We called such approach \emph{deep embedding}, compared to the \emph{shallow 
%	embedding} approach what we are going to propose).
%In deep embedding, the derivability relation is captured by a \emph{binary} 
%predicate symbol that takes representations of a pattern and a theory as its 
%two arguments.
%The reason we adopt shallow embedding in this proposal instead of deep 
%embedding is more of practical concerns.
%\todo{another benefit of shallow embedding is that it captures the ``smallest 
%fixed points'' semantics of parametric sorts.}
%In shallow embedding, we do not need to develop infrastructure that 
%``encapsulate'' (possibly) infinite signatures and theories as (definitely) 
%finite terms, which results in a more light-weighted meta-theory.
%However, shallow embedding brings some inconvenience, too. The 
%lack of representation of signatures and theories in the meta-theory makes it 
%impossible to axiomatize module operations---such as joining two modules and 
%hiding a module from the other---within the meta-theory.
%
%Given said that, such inconvenience should never become a theoretical obstacle.
%\todo{because we can reflect the meta-theory in itself.}


\subsection{Faithfulness}

\begin{theorem}[Faithfulness Theorem]\label{thm:faithfulness-finite}
	Given a matching logic theory $T$ and a naming function,
	$$T \vdash \varphi \quad \text{iff} \quad K \cup \denote{T} \vdash 
	\Kdeduce(\denote{\varphi}).$$
\end{theorem}

Theorem~\ref{thm:faithfulness-finite} is an important theorem that justifies the design and usage of the theory $\Kfinite$. 
It guarantees that the theory $\Kfinite$ does faithfully capture the matching logic reasoning in finite theories.


\section{The Kore Language}

The Kore language is a formal specification language that allows one to specify (finite or r.e. infinite) theories using a finite number of characters and words.
The syntax of Kore is designed to be very simple, as we will see in Section~\cref{sec:kore-syntax}.

We recall the readers of upward and downward reflection relations
\begin{center}
	\begin{tabular}{cc}
		$
		\prftree[r]{\footnotesize (Upward Reflection)}
		{T \vdash \varphi}
		{K \cup \denote{T} \vdashfin \Kdeduce(\denote{\varphi})}
		$
		&
		$
		\prftree[r]{\footnotesize (Downward Reflection)}
		{K \cup \denote{T} \vdashfin \Kdeduce(\denote{\varphi})}
		{T \vdash \varphi}
		$
	\end{tabular}
\end{center}
What Kore does is to give users a nice way to specify $\denote{T}$ without getting exposed to too much staffs in the meta-theory.
Users are free to write things at the object-level and Kore will lift those to the meta-theory automatically.
In other words, the semantics of Kore is given by lifting itself to the meta-theory.


\subsection{Syntax}

\subsubsection{Lexicon}
\label{sec:kore-lexicon}

A Kore definition file is a sequence of ASCII characters

a comment is ...


Lexicon tokens are
\begin{center}
	\begin{tabular}{c|l|l}
		\textbf{Token Character} & \textbf{Name} & \textbf{Used In}
		\\\hline
		\texttt{:} & Colon & Variables and Declarations
		\\
		\texttt{\string{ \string}} & Curly Braces & Parameters
		\\
		\texttt{( )} & Parenthesis & Kore Expressions
		\\
		\texttt{:=} & Colon Equal & Alias Declarations
	\end{tabular}
\end{center}

Syntactic categories are introduced and defined in the following.

\paragraph{White Space Characters.}
\paragraph{Printable Characters.}
\paragraph{Digits}
\paragraph{Letters}


\paragraph{Reserved Logical Connectives and Derived Connectives.}
\begin{center}
\begin{tabular}{llll}
    \sland & or & \slexists & \slforall \\
	\slnot & \slimplies & \sliff & \slequals \\
	\slceil & \slfloor & \sltop & \slbottom
\end{tabular}
\end{center}

\paragraph{Reserved Keywords}
\begin{center}
	{\ttfamily
	\begin{tabular}{lllllll}
		sort & hooked-sort & symbol & hooked-symbol & alias & hooked-alias &
		axiom
\end{tabular}}
\end{center}

\paragraph{String Literals.}
``Anything'' that is wrapped with quotation marks.

\subsubsection{Identifiers}

\paragraph{Object Identifiers.}
A non-empty sequence of characters that does not start with a ``\shp\,''.

\paragraph{Meta-Identifiers.}
A non-empty sequence of characters that starts with a ``\shp\,''.


\paragraph{Reserved Identifiers.}
Meta-identifiers that are either a sort or a symbol in the meta-theory, $K$. For example, \verb|#Sort|, \verb|#\and|.

\subsubsection{Parameters}

\subsubsection{Sorts}

\subsubsection{Symbols and Aliases}

\subsubsection{Patterns}

\subsubsection{Kore Declarations}
Kore declarations can be either one of the follows:
\begin{itemize}\itemsep0em
	\item Sort declaration
	\item Symbol declaration
	\item Axiom declaration
	\item Alias declaration
\end{itemize}
each of which declares a sort, a symbol, an axiom, or an alias respectively.

\subsection{Semantics}
\subsubsection{Distinguish Meta-Level from Object Level}
\subsubsection{Identifiers To String Literals}
\subsubsection{Lifting Patterns}
\begin{algorithm}[h]
	\KwIn{An object-pattern $\varphi$.}
	\KwOut{The meta-representation (ASTs) of $\varphi$ in $K$}
	\uIf{$\varphi$ is $x \cln s$}{Return $\mathit{variable(x, sort(s))}$}
	\uElseIf{$\varphi$ is $x \cln \cln s$}{Return $x \cln \KPattern {\ \wedge\ 
		} (\mathit{sort(s)} = \KgetSort(x \cln \KPattern)) $}
	\uElseIf{$\varphi$ is $\varphi_1 \wedge \varphi_2$}
	{Return $\Kand(\mathit{lift}[\varphi_1], \mathit{lift}[\varphi_2]$}
	\uElseIf{$\varphi$ is $\neg \varphi_1$}
	{Return $\Knot(\mathit{lift}[\varphi_1])$}
	\uElseIf{$\varphi$ is $\exists x \cln s . \varphi_1$}
	{Return $\Kexists(x, \mathit{sort(s)}, \mathit{lift}[\varphi_1])$}
	\uElseIf{$\varphi$ is $\sigma(\varphi_1,\dots,\varphi_n)$ and $\sigma \in 
		\Sigma_{s_1,\dots,s_n,s}$}
	{Return $\Kapplication(\mathit{symbol}(\sigma, (\Ksort(s_1), \dots, 
		\Ksort(s_n)), \Ksort(s)),$
		$\mathit{lift}[\varphi_1],\dots,\mathit{lift}[\varphi_n])$}
	\caption{Lifting Function $\mathit{lift}[\_]$}
	\label{alg:liftingfunction}
\end{algorithm}
\subsubsection{Lifting Declarations}
\subsection{Get Things From Here}

\subsubsection{Formal BNF Grammar of Kore}

\begin{grammar}\small
	<definition>    ::= <declarations>
	
	<declarations> ::= `' | <declaration> | <declaration> <declarations>
	
	<declaration>   ::= \quad
	\alt <sort-declaration> 
	\alt <symbol-declaration> 
	\alt <axiom-declaration>
	\alt <alias-declaration>
	
	<sort-declaration> ::= \quad
	\alt `sort' <sort>
	\alt `hooked-sort' <sort> 
	
	<sort> ::= \quad
	\alt <atomic-sort> 
	\alt <parametric-sort>
	
	<parametric-sort> ::= \quad
	\alt <parametric-sort-constructor> `{' <sort-list> `}'
	
	<sort-list> ::= \quad 
	\alt <sort> 
	\alt <sort> `,' <sort-list>
	
	<atomic-sort> ::= "[A-Z][a-zA-Z0-9]"$^+$
	
	<sort-variable> ::= "[A-Z0-9]"$^+$
	
	<parametric-sort-constructor> ::= "[A-Z][a-zA-Z0-9]"$^+$
	
	<symbol-declaration> ::= \quad
	\alt `symbol' <symbol> <symbol-signature>
	\alt `hooked-symbol' <symbol> <symbol-signature>
	
	<symbol> ::= \quad
	\alt <nonparametric-symbol>
	\alt <parametric-symbol>
	
	<nonparametric-symbol> ::= "[a-zA-Z0-9]"$^+$
	
	<parametric-symbol> ::= \quad
	\alt <parametric-symbol-name> `{' <sort-list> `}'
	
	<parametric-symbol-name> ::= "[a-zA-Z0-9]"$^+$
	
	<symbol-signature> ::= \quad
	\alt `(' <sort-list> `)' `:' <sort>
	
	<axiom-declaration> ::= \quad
	\alt `axiom' <pattern>
	
	<pattern> ::= \quad
	\alt <variable-name> `:' <sort>
	\alt <symbol> `(' <pattern-list> `)'
	\alt `\\and' `(' <pattern> `,' <pattern> `,' <sort> `)'
	\alt `\\not' `(' <pattern> `,' <sort> `)' 
	\alt `\\exists' `(' <variable-name> `:' <sort> `,' <pattern> `,' <sort> `)'
	\alt "how to denote meta-variables?"
	
	<pattern-list> ::= \quad
	\alt `' 
	\alt <pattern> 
	\alt <pattern> `,' <pattern-list>
	
	<alias-declaration> ::= \quad
	\alt `alias' "todo here, check the following example of IMP."
\end{grammar}

\todo[inline]{Show how to lift a Kore definition: (1) the default naming function Nat $\longrightarrow$ ``Nat'' (2) the default sugar symbols at the meta-level Nat $\longrightarrow$ KNat, succ $\longrightarrow$ Ksucc, etc. (3) the lifting function}


\section{IMP in Kore}
As an example, we present the semantics of IMP defined as a Kore definition.
\lstinputlisting[language=kore]{imp.kore}

\section{Proof of Faithfulness Theorem}
Before we start to prove the theorem, we need to explain what ``the 
corresponding patterns'' $\hat{T}$ and $\hat{\varphi}$ are, as they appear in 
the theorem.
For that reason, we introduce the next definition.

\begin{definition}[Naming and Lifting]
	Suppose $T = (S, \Sigma, A)$ is a finite matching logic theory, with $\Var 
	= \bigcup_{s \in S} \Var_s$ is the set of all variables of $T$.
	\emph{A naming of $T$}, denoted as $e$, consists of the following three 
	naming functions
	\begin{itemize}
		\item A sort-naming function $e_S \colon S \to \PATTERNS_\KString$ that 
		maps each sort in $S$ to a syntactic $\KString$ pattern such that $K 
		\vdash e_S(s_1) \neq e_S(s_2)$ for any distinct sorts $s_1$ and $s_2$;
		\item A symbol-naming function $e_\Sigma \colon \Sigma \to 
		\PATTERNS_\KString$ that maps each symbol in $\Sigma$ to a syntactic 
		$\KString$ pattern such that $K \vdash e_\Sigma(\sigma_1) \neq 
		e_\Sigma(\sigma_2)$ for any distinct symbols $\sigma_1$ and $\sigma_2$;
		\item A variable-naming function $e_\Var \colon \Var \to 
		\PATTERNS_\KString$ that maps each variable in $T$ to a syntactic 
		$\KString$ pattern in $K$, such that $K \vdash e_\Var(x) \neq 
		e_\Var(y)$ for any distinct variables $x$ and $y$.
	\end{itemize}
	
	Given $e = \{e_S, e_\Sigma, e_\Var \}$ is a naming of theory $T$, the 
	\emph{lift of $T$ with respect to $e$} consists of the following lifting 
	functions.
	
	(Sort-lifting).
	For each sort $s$ in theory $T$, the lift of $s$ is a $\KSort$ pattern
	$$ \hat{s} = \Ksort(e_S(s))$$
	
	(Symbol-lifting).
	For each symbol $\sigma \in \Sigma_{s_1 \dots s_n, s}$, the lift of 
	$\sigma$ is a $\KSymbol$ pattern 
	$$ \hat{\sigma} = \Ksymbol(e_\Sigma(\sigma), (\hat{s_1}, \dots, \hat{s_n}), 
	\hat{s})$$
	
	(Pattern-lifting).
	For each $\Sigma$-pattern $\varphi$, the lift of $\varphi$ is a $\KPattern$ 
	pattern inductively defined as follows
	\begin{equation*}
	\hat{\varphi} =
	\begin{cases*}
	\Kvariable(e_\Var(x), \hat{s}) & if $\varphi$ is a variable $x \in \Var_s 
	\subseteq \PATTERNS_s$
	\\
	\Kapplication(\hat{\sigma}, (\hat{\psi_1}, \dots, \hat{\psi_n})) & if 
	$\varphi$ is $\sigma(\psi_1,\dots,\psi_n) \in \PATTERNS_s$
	\\
	\Kand(\hat{\psi_1}, \hat{\psi_2}, \hat{s}) & if $\varphi$ is $\psi_1 \wedge 
	\psi_2 \in \PATTERNS_s$
	\\
	\Knot(\hat{\psi}, \hat{s}) & if $\varphi$ is $\neg \psi \in \PATTERNS_s$
	\\
	\Kexists(e_\Var(x), \hat{s_1}, \hat{\psi}, \hat{s_2}) & if $\varphi$ is 
	$\exists x . \psi \in \PATTERNS_{s_2}$ and $x \in \Var_{s_1}$
	\end{cases*}
	\end{equation*}
	
	(Theory-lifting). Since $T = (S, \Sigma, A)$ is a finite theory, let us 
	suppose
	\begin{equation*}
	S = \{ s_1, \dots, s_n \}, 
	\Sigma = \{ \sigma_1, \dots, \sigma_m \}, 
	A = \{ \varphi_1, \dots, \varphi_k \},
	\end{equation*}
	are three finite sets. The lift of theory $T$ is a $\KTheory$ pattern 
	$$ \hat{T} = \Ktheory(\Ksignature(\hat{S}, \hat{\Sigma}), \hat{A}),$$
	where the lifts of $S$, $\Sigma$, and $A$ are respectively defined as
	\begin{align*}
	& \hat{S} = \hat{s_1},\dots,\hat{s_n} 
	\quad \text{is a $\KSortList$ pattern}
	\\
	& \hat{\Sigma} = \hat{\sigma_1},\dots,\hat{\sigma_m}
	\quad \text{is a $\KSymbolList$ pattern}
	\\
	& \hat{A} = \hat{\varphi_1}, \dots, \hat{\varphi_k}
	\quad \text{is a $\KPatternList$ pattern}
	\end{align*}
\end{definition}

In order to prove Theorem~\ref{thm:faithfulness-finite}, we introduce a 
canonical model of $\Kfinite$.

\begin{definition}[Canonical model of $\Kfinite$]
	The canonical model of $\Kfinite$, denoted as $M_\Kfinite$, contains  
	carrier sets (for each sort in $S_\Kfinite$) and relations (for each 
	symbols in $\Sigma_\Kfinite$) that are defined in the following.
	
	The carrier set for the sort $\KPred$ is a singleton set $M_\KPred = \{ 
	\star \}$. 
	
	The carrier set for the sort $\KChar$ is the set of all 62 constructors of 
	the sort $\KChar$, denoted as $M_\KChar$.
	
	The carrier set for the sort $\KString$ is the set of all syntactic 
	patterns of the sort $\KString$, denoted as $M_\KString$.
	
	The carrier set for the sort $\KSort$ is the set of all syntactic patterns 
	of the sort $\KSort$ 
	$$M_\KSort = \{ \Ksort(str) \mid str \in M_\KString \}.$$
	
	The carrier set for the sort $\KSortList$ is the set of all finite lists of 
	$M_\KSort$:
	$$M_\KSortList = (M_\KSort)^*.$$
	
	The carrier set for the sort $\KSymbol$ is the set of all syntactic 
	patterns of the sort $\KSymbol$
	$$M_\KSymbol = \{ \Ksymbol(str, l, s) \mid str \in M_\KString, l \in 
	M_\KSortList, s \in M_\KSort \}.$$
	
	The carrier set for the sort $\KSymbolList$ is the set of all finite lists 
	over $M_\KSymbol$:
	$$M_\KSymbolList = (M_\KSymbol)^* .$$
	
	The carrier set for the sort $\KPattern$ is the set of all syntactic 
	patterns of the sort $\KPattern$, denoted as $M_\KPattern$.
	
	The carrier set for the sort $\KPatternList$ is the set of all finite lists 
	over $M_\KPattern$:
	$$M_\KPatternList = (M_\KPattern)^*.$$
	
	The carrier set for the sort $\KSignature$ is a product set
	$$ M_\KSignature = M_\KSortList \times M_\KSymbolList.$$
	
	The carrier set for the sort $\KTheory$ is a product set
	$$ M_\KTheory = M_\KSignature \times M_\KPattern. $$
	
	The interpretations of most symbols (except $\Kdeduce$) in $\Kfinite$ are 
	so straightforward that they are trivial.\improvement{Basically I want to 
	say that $M_K$ is almost (except $Kprovable$) the initial algebra of $\Kfinite$.}
	For example, $\KconsKSortList$ is interpreted as the cons function on 
	$M_\KSortList$, and $\KdeleteKPatternList$ is interpreted as a function on 
	$M_\KPattern \times M_\KPatternList$ that deletes the first argument from 
	the second, etc.
	
	The only nontrivial interpretation is the one for $\Kdeduce$, as we would 
	like to interpret it \emph{in terms of} matching logic reasoning.
	The interpretation of $\Kdeduce$ in the canonical model is a predicate on 
	$M_\KTheory$ and $M_\KPattern$.
	Intuitively, $\Kdeduce_M(T, \varphi)$ holds if both $T$ and $\varphi$ are 
	well-formed and $\varphi$ is deducible in the finite matching logic theory 
	$T$.
	This intuition is captured by the next formal definition.
	
	For any $T = (\Sigma, A) \in M_\KTheory$ and $\varphi \in M_\KPattern$, we 
	define
	\begin{equation*}
	\Kdeduce_M(T, \varphi) =
	\begin{cases*}
	\emptyset & if $\KwellFormed_M(\Sigma, \varphi) = \emptyset$
	\\
	\{ \star \} & if $\Bracket{T} \vdash \Bracket{\varphi}$
	\\
	\emptyset & if $\Bracket{T} \not\vdash \Bracket{\varphi}$
	\end{cases*}
	\end{equation*}
	where the \emph{semantics bracket} $\Bracket{\_}$ is defined (only on 
	well-formed $T$ and $\varphi$) as follows:
	\begin{center}\begin{tabular}{l}
			$\Bracket{T}$ is the matching logic theory $(\Sigma, \Bracket{A})$ 
			\\
			$\Bracket{A} = \{ \Bracket{\psi} | \mid \psi \in A \}$ \\
			$\Bracket{\varphi} =
			\begin{cases*}
			x \cln s & if $\varphi$ is $\Kvariable(x, s)$ \\
			\sigma(\Bracket{\varphi_1},\dots,\Bracket{\varphi_n}) & if 
			$\varphi$ is $\Kapplication(\sigma, (\varphi_1,\dots,\varphi_n))$\\
			\Bracket{\varphi_1} \wedge \Bracket{\varphi_2} & if $\varphi$ is 
			$\Kand(\varphi_1,\varphi_2,s)$,\\
			\neg \Bracket{\varphi_1} & if $\varphi$ is $\Knot(\varphi_1, s)$\\
			\exists x . \Bracket{\varphi_1} & if $\varphi$ is $\Kexists(x, s_1, 
			\varphi_1, s_2)$
			\end{cases*}$
	\end{tabular}\end{center}
	
	It is tedious but straightforward to verify that $\Kdeduce_M$ satisfies all 
	axioms about $\Kdeduce$ that we introduced in 
	Section~\cref{sec:ml-proof-system-finite-case}.
	For example, the Rule (K1)
	\begin{equation*}
	\Kdeduce(T, \overline{\varphi \leftrightarrow_s (\psi \leftrightarrow_s 
	\varphi)})
	\end{equation*}
	holds in $\Kfinite$ because
	$$\Bracket{T} \vdash \Bracket{\varphi} \to (\Bracket{\psi} \to 
	\Bracket{\varphi})$$
	The Rule (Modus Ponens)
	\begin{equation*}
	\Kdeduce(T, \varphi) \wedge \Kdeduce(T, \overline{\varphi \leftrightarrow_s 
	\psi}) \to 
	\Kdeduce(T, \psi)
	\end{equation*}
	holds in $\Kfinite$ because
	$$\text{if $\Bracket{T} \vdash \Bracket{\varphi}$ and $\Bracket{T} \vdash 
	\Bracket{\varphi} \to \Bracket{\psi}$, then $\Bracket{T} \vdash 
	\Bracket{\psi}$}.$$
	
	Readers are welcomed to verify the remaining axioms in $\Kfinite$ also hold 
	in $M_K$.
	We omit them here.
	
	
\end{definition}


Now we are in a good shape to prove Theorem~\ref{thm:faithfulness-finite}.

\begin{proof}[Proof Sketch of Theorem~\ref{thm:faithfulness-finite}]\quad
	
	Step 1 (The ``$\Rightarrow$'' part). 
	
	We prove this by simply mimicking the proof of $T \vdash \varphi$ in 
	$\Kfinite$.
	
	Step 2 (The ``$\Leftarrow$'' part).
	
	Let us fix a finite matching logic theory $T = (S, \Sigma, A)$, a 
	$\Sigma$-pattern $\varphi$, and an encoding $e$, and assume that $\Kfinite 
	\vdash \Kdeduce(\hat{T}, \hat{\varphi})$.
	Since the matching logic proof system is sound, the interpretation of 
	$\Kdeduce(\hat{T}, \hat{\varphi})$ should hold in the canonical model $M_K$:
	$$ \Kdeduce_M(\hat{T}, \hat{\varphi}) = \{ \star \}. $$
	By definition, this means that
	$$\Bracket{\hat{T}} \vdash \Bracket{\hat{\varphi}}.$$
	
	Finally notice that by construction of encoding, lifting, and the semantics 
	bracket, there is an isomorphism between $T$ and  $\Bracket{\hat{T}}$, so 
	from $\Bracket{\hat{T}} \vdash \Bracket{\hat{\varphi}}$ we have
	$$T \vdash \varphi.$$
	
	\fbox{\begin{minipage}{35em}\color{blue}\small
			The following a snapshot of what we had on the board:
			
			Step 2.1. Fix a finite matching logic theory $T = (S, \Sigma, A)$ 
			and a $\Sigma$-pattern $\varphi$. 
			
			Step 2.2. Build a model $M_{T}$ based on $T = (S, \Sigma, A)$.
			
			Step 2.3. Show that $M_T$ is a model of $\Kfinite$.
			
			Step 2.4. Interpret $\Kdeduce(\hat{T}, \hat{\varphi})$ in $M_T$ and 
			get $T 
			\vDash \varphi$.
	\end{minipage}}
\end{proof}


\bibliographystyle{abbrv}
\bibliography{refs}

\section{Get Material From Here}

Matching logic imposes no restrictions on the cardinality of the set of
sorts $S$, of the set of symbols $\Sigma$, or of the set of patterns $A$
in a theory $(S,\Sigma,A)$.
In practice, however, we need a finite mechanism to describe such theories
in order to mechanically reason about them using a computer.
In the vast universe of possibilities, we here propose one particular approach
that we found useful, convenient and sufficient in our semantics engineering
efforts.
Specifically:
\begin{itemize}
	\item
	We restrict the infinite sets of sorts to ones which can be described with
	a finite set of \emph{parametric} sorts, where the parameters range over
	other sorts.
	For example, $S=\{\Nat,\parametric{\List}{X}\}$ describes the infinite set
	of sorts
	$S=\{\Nat, \parametric{\List}{\Nat}, 
	\parametric{\List}{\parametric{\List}{\Nat}}, ...\}$.
	
\end{itemize}

From here on, unless otherwise specified, when we say \emph{set} we mean
a \emph{recursively enumerable set}, i.e., a set that can be generated
algorithmically (not to be confused with the weaker notion of a
countable\unsure{countable may suffice, we'll need to understand how it is in 
FOL}
set, which only means that it has a cardinal no larger than
$\aleph_0$---either finite or in bijection with the set
of natural numbers).


In this section, we define a matching logic theory $K = (S_K, \Sigma_K, A_K)$ 
as \emph{the (reflective) calculus of matching logic},
where $S_K, \Sigma_K$, and $A_K$ are \emph{finite} sets of sorts,
symbols, and axioms,  respectively.

Sorts are declared using the \sort keyword, symbols are declared using the 
\symb keyword, and axioms are defined using the \axiom keyword.

\begin{Verbatim}[fontsize=\small]
// Namespaces for sorts, variables, metavariables,
// symbols, and Kore modules.
Sort           = String
VariableId     = String
MetaVariableId = String
Symbol         = String
ModuleId       = String

Variable       = VariableId:Sort
MetaVariable   = MetaVariableId::Sort

Pattern        = Variable | MetaVariable
| \and(Pattern, Pattern)
| \not(Pattern)
| \exists(Variable, Pattern)
| Symbol(PatternList)

Sentence       = import ModuleId
| syntax Sort
| syntax Sort ::= Symbol(SortList)
| axiom Pattern
Sentences      = Sentence | Sentences Sentences

Module         = module ModuleId
Sentences
endmodule
\end{Verbatim}

In Kore syntax, the backslash ``\verb|\|'' is reserved for matching logic 
connectives and the sharp ``\verb|#|'' is reserved for the meta-level, i.e., 
the $K$ sorts and symbols. 
Therefore, the sorts $\KPred$, $\KString$, $\KSymbol$, $\KSort$, and 
$\KPattern$ in the calculus $K$ are denoted as \verb|#Bool|, \verb|#String|, 
\verb|#Symbol|, \verb|#Sort|, and \verb|#Pattern| in Kore respectively.
Symbols in $K$ are denoted in the similar way, too. 
For example, the constructor symbol $\Kvariable \colon \KString \times \KSort 
\to \KPattern$ is denoted as \verb|#variable| in Kore. 

A Kore module definition begins with the keyword \verb|module| followed by the 
name of the module-being-defined, and ends with the keyword \verb|endmodule|. 
The body of the definition consists of some \emph{sentences}, whose meaning are 
introduced in the following.

The keyword \verb|import| takes an argument as the name of the 
module-being-imported, and looks for that module in previous definitions. 
If the module is found, the body of that module is copied to the current module.
Otherwise, nothing happens. 
The keyword \verb|syntax| leads a \emph{syntax declaration}, which can be 
either a \emph{sort declaration} or a \emph{symbol declaration}.
Sorts declared by sort declarations are called \emph{object-sorts}, in 
comparison to the five \emph{meta-sorts}, \verb|#Bool|, \verb|#String|, 
\verb|#Symbol|, \verb|#Sort|, and \verb|#Pattern|, in $K$. 
Symbols whose argument sorts and return sort are all object-sorts (meta-sorts) 
are called \emph{object-symbols} (\emph{meta-sorts}).

Patterns are written in prefix forms. 
A pattern is called an \emph{object-pattern} (\emph{meta-pattern}) if all sorts 
and symbols in it are object (meta) ones.
Meta-symbols will be added to the calculus $K$, while object-sorts and 
object-symbols will not.
They only serve for the purpose to parse an object pattern. 

The keyword \verb|axiom| takes a pattern and adds an axiom to the calculus $K$.
If the pattern is a meta-pattern, it adds the pattern itself as an axiom.
If the pattern $\varphi$ is an object-pattern, it adds $\Bracket{\varphi}$ as 
an axiom to the calculus $K$.

Recall that we have defined the semantics bracket as
\begin{equation*}
\Bracket{\varphi} \equiv 
\left(\textit{deducible}\left(\mathit{lift}[\varphi]\right) = true\right),
\end{equation*}
where $\varphi$ is a pattern of the grammar in Figure~\ref{ml-grammar}.
However, here in Kore we allow $\varphi$ containing \emph{meta-variables}.
As a result, we modify the definition of the semantics bracket as 
$$\Bracket{\varphi} \equiv \mathit{mvsc}[\varphi] \to 
(deducible\left(\mathit{lift}[\varphi]\right) = true),$$
where the lifting function $\mathit{lift}[\_]$ and the meta-variable sort 
constraint $\mathit{mvsc}[\_]$ are defined in 
Algorithm~\ref{alg:liftingfunction} and~\ref{alg:mvsc}, respectively.
Intuitively, meta-variables in an object-pattern $\varphi$ are lifted to 
variables of the sort $\KPattern$ with the corresponding sort constraints. 
For example, the meta-variable $x \cln\cln s$ is lifted to a variable $x \cln 
\KPattern$ in $K$ with the constraint that $\KgetSort(x \cln \KPattern) = 
sort(s)$. The function $\mathit{mvsc}[\_]$ collects all such meta-variable sort 
constraint in an object-pattern is implemented in Algorithm~\ref{alg:mvsc}.



\begin{algorithm}
	\KwIn{An object-pattern $\varphi$}
	\KwOut{The meta-variable sort constraint of $\varphi$}
	Collect in set $W$ all meta-variables appearing in $\varphi$\;
	Let $C = \emptyset$\;
	\ForEach{$x \cln \cln s \in W$}
	{$C = C \cup (\mathit{sort(s)} = \KgetSort(x \cln \KPattern))$}
	Return $\bigwedge C$\;
	\caption{Meta-Variable Sort Constraint Collection $\mathit{mvsc}$}
	\label{alg:mvsc}
\end{algorithm}

\end{document}
